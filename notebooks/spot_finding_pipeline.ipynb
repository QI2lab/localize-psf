{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pipeline to find spot in a single non-skewed xyz image tile.\n",
    "The global plan is:\n",
    "  - [x] spot detection working on single non-skewed tile, no GPU, no multiprocess, no coordinates change, no file handling\n",
    "    - [x] extract single ct xyz tile with spots\n",
    "  - [x] add multiple tiles (x, y, z vary), \"stich\" results with orthogonal change of coordinates\n",
    "  - [ ] add multiple time steps, channels (need different parameters per channel)\n",
    "  - [x] add Dask support per xyztc tile and merge results\n",
    "  - [ ] add GPU support per tile? Manage conflict with multi-processes tile handling.\n",
    "  - [ ] add support for skewed tiles\n",
    "    - [x] extract tilted tile\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900036aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "from tifffile import tifffile\n",
    "import zarr\n",
    "import dask.array as da\n",
    "from dask_image.imread import imread\n",
    "from dask import delayed\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "from pycromanager import Dataset\n",
    "import napari\n",
    "from napari.qt.threading import thread_worker\n",
    "from magicgui import magicgui\n",
    "# from matplotlib.colors import PowerNorm, LinearSegmentedColormap, Normalize\n",
    "from tiler import Tiler\n",
    "from tysserand import tysserand as ty\n",
    "# from mosna import mosna as mo\n",
    "\n",
    "import localize_psf.rois as roi_fns\n",
    "from localize_psf import fit\n",
    "import localize_psf.fit_psf as psf\n",
    "from localize_psf import localize\n",
    "import localize_skewed\n",
    "import image_post_processing as ipp\n",
    "from image_post_processing import deskew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784cb4d",
   "metadata": {},
   "source": [
    "## On single deskewed tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed8710",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81fb02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 9833, 1584)\n",
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "dir_load = Path('../../../from_server/example_image_deskewed')\n",
    "round = 1\n",
    "channel = 2\n",
    "tile = 0\n",
    "\n",
    "path_im = dir_load / 'round-{}_channel-{}_tile-{}.zarr'.format(round, channel, tile)\n",
    "im = da.from_zarr(str(path_im))\n",
    "# im = da.moveaxis(im, 1, 0)\n",
    "print(im.shape)\n",
    "# img = im[:, 1000:1512, 512:1024].compute()\n",
    "# img = im[:, 1000:1256, 512:768].compute()\n",
    "start_x = 512\n",
    "start_y = 1000\n",
    "size_xy = 128\n",
    "img = im[128:2*128, start_y:(start_y+size_xy), start_x:(start_x+size_xy)].compute()\n",
    "print(img.shape)\n",
    "mini = img.min() # 0\n",
    "maxi = img.max()\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(\n",
    "#     img, \n",
    "#     contrast_limits=[mini, maxi], \n",
    "#     name='ch_' + str(channel), \n",
    "#     # colormap=color, \n",
    "#     blending='additive',\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8dcea",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Parameters from Peter's code\n",
    "\n",
    "Code is:\n",
    "```python                   \n",
    "###############################\n",
    "identify candidate points in opm data\n",
    "###############################\n",
    "sigma_xy = 0.22 * emission_wavelengths[ch] / na\n",
    "sigma_z = np.sqrt(6) / np.pi * ni * emission_wavelengths[ch] / na ** 2\n",
    "sigma_xy = psf.na2sxy(na, emission_wavelengths[ch])\n",
    "sigma_z = psf.na2sz(na, emission_wavelengths[ch], ni)\n",
    "\n",
    "difference of gaussian filer\n",
    "filter_sigma_small = (0.5 * sigma_z, 0.25 * sigma_xy, 0.25 * sigma_xy)\n",
    "filter_sigma_large = (3 * sigma_z, 3 * sigma_xy, 3 * sigma_xy)\n",
    "fit roi size\n",
    "roi_size = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "assume points closer together than this come from a single bead\n",
    "min_spot_sep = (3 * sigma_z, 3 * sigma_xy)\n",
    "exclude points with sigmas outside these ranges\n",
    "sigmas_min = (0.25 * sigma_z, 0.25 * sigma_xy)\n",
    "sigmas_max = (3 * sigma_z, 4 * sigma_xy)\n",
    "```\n",
    "\n",
    "With na=1.0 and ni=1.4  \n",
    "For ch 0:  \n",
    "    - emission_wavelengths: 0.515  \n",
    "    - sigma_xy: 0.123  \n",
    "    - sigma_z: 0.562  \n",
    "    - filter_sigma_small: [0.281 0.031 0.031]  \n",
    "    - filter_sigma_large: [1.686 0.368 0.368]  \n",
    "    - roi_size: [2.811 1.472 1.472]  \n",
    "    - min_spot_sep: [1.686 0.368]  \n",
    "    - sigmas_min: [0.141 0.031]  \n",
    "    - sigmas_max: [1.686 0.491]  \n",
    "\n",
    "For ch 1:  \n",
    "    - emission_wavelengths: 0.6  \n",
    "    - sigma_xy: 0.143  \n",
    "    - sigma_z: 0.655  \n",
    "    - filter_sigma_small: [0.327 0.036 0.036]  \n",
    "    - filter_sigma_large: [1.965 0.429 0.429]  \n",
    "    - roi_size: [3.275 1.715 1.715]  \n",
    "    - min_spot_sep: [1.965 0.429]  \n",
    "    - sigmas_min: [0.164 0.036]  \n",
    "    - sigmas_max: [1.965 0.572]  \n",
    "\n",
    "For ch 2:  \n",
    "    - emission_wavelengths: 0.68  \n",
    "    - sigma_xy: 0.162  \n",
    "    - sigma_z: 0.742  \n",
    "    - filter_sigma_small: [0.371 0.04  0.04 ]  \n",
    "    - filter_sigma_large: [2.227 0.486 0.486]  \n",
    "    - roi_size: [3.711 1.944 1.944]  \n",
    "    - min_spot_sep: [2.227 0.486]  \n",
    "    - sigmas_min: [0.186 0.04 ]  \n",
    "    - sigmas_max: [2.227 0.648]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca500bb",
   "metadata": {},
   "source": [
    "### DoG filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed58fa56",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# size of spots in pixels\n",
    "sx = sy = 5\n",
    "sz = 20\n",
    "# FWHM = 2.355 x sigma\n",
    "sigma_xy = sx / 2.355\n",
    "sigma_z = sz / 2.355\n",
    "# to reproduce LoG with Dog we need sigma_big = 1.6 * sigma_small\n",
    "sigma_xy_small = sigma_xy / 1.6**(1/2)\n",
    "sigma_xy_large = sigma_xy * 1.6**(1/2)\n",
    "sigma_z_small = sigma_z / 1.6**(1/2)\n",
    "sigma_z_large = sigma_z * 1.6**(1/2)\n",
    "\n",
    "filter_sigma_small = (sigma_z_small, sigma_xy_small, sigma_xy_small)\n",
    "filter_sigma_large = (sigma_z_large, sigma_xy_large, sigma_xy_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063aedb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - sx: 5  \n",
      "  - sz: 20  \n",
      "  - sigma_xy: 2.123  \n",
      "  - sigma_z: 8.493  \n",
      "  - sigma_xy_small: 1.678  \n",
      "  - sigma_xy_large: 2.686  \n",
      "  - sigma_z_small: 6.714  \n",
      "  - sigma_z_large: 10.742  \n"
     ]
    }
   ],
   "source": [
    "print(f\"  - sx: {np.round(sx, 3)}  \")\n",
    "print(f\"  - sz: {np.round(sz, 3)}  \")\n",
    "print(f\"  - sigma_xy: {np.round(sigma_xy, 3)}  \")\n",
    "print(f\"  - sigma_z: {np.round(sigma_z, 3)}  \")\n",
    "print(f\"  - sigma_xy_small: {np.round(sigma_xy_small, 3)}  \")\n",
    "print(f\"  - sigma_xy_large: {np.round(sigma_xy_large, 3)}  \")\n",
    "print(f\"  - sigma_z_small: {np.round(sigma_z_small, 3)}  \")\n",
    "print(f\"  - sigma_z_large: {np.round(sigma_z_large, 3)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea865af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_sizes = (1, 1, 1)\n",
    "kernel_small = localize.get_filter_kernel(filter_sigma_small, pixel_sizes, sigma_cutoff=2)\n",
    "kernel_large = localize.get_filter_kernel(filter_sigma_large, pixel_sizes, sigma_cutoff=2)\n",
    "\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(kernel_small, name='kernel small', colormap='green', blending='additive')\n",
    "# viewer.add_image(kernel_large, name='kernel large', colormap='red', blending='additive')\n",
    "\n",
    "# %%Can we skip the second convulotion with an \"normalized\" kernel?\n",
    "# im_fct = scipy.signal.fftconvolve(img, kernel_small, mode=\"same\") / scipy.signal.fftconvolve(np.ones(img.shape), kernel_small, mode=\"same\")\n",
    "# kernel_small_normalized = kernel_small - kernel_small.mean()\n",
    "# im_normalized = scipy.signal.fftconvolve(img, kernel_small_normalized, mode=\"same\")\n",
    "\n",
    "\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(im_fct, name='im_fct')\n",
    "# viewer.add_image(im_normalized, name='im_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39a28b6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "img_high_pass = localize.filter_convolve(img, kernel_small, use_gpu=False)\n",
    "img_low_pass = localize.filter_convolve(img, kernel_large, use_gpu=False)\n",
    "img_filtered = img_high_pass - img_low_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08224d83",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img_filtered' at 0x7faa93786c40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_high_pass, name='img_high_pass')\n",
    "viewer.add_image(img_low_pass, name='img_low_pass')\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30432cf5",
   "metadata": {},
   "source": [
    "### Threshold DoG and local max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd43001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold found with Napari\n",
    "dog_thresh = 4\n",
    "img_filtered[img_filtered < dog_thresh] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd27acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_separations = (10, 3, 3)\n",
    "\n",
    "footprint = localize.get_max_filter_footprint(min_separations=min_separations, drs=pixel_sizes)\n",
    "# array of size nz, ny, nx of True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bf0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test:\n",
    "# maxis = scipy.ndimage.maximum_filter(img_filtered, footprint)\n",
    "# maxis = scipy.ndimage.maximum_filter(img_filtered, footprint=np.ones(min_separations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae669dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(maxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15f7ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad161972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could remove the thresholding within each find_peak_candidates call\n",
    "# no: ndimage.maximum_filter returns same image size with real values, need image == im_max\n",
    "# thus need to filter with threshold to avoid zeros or low values\n",
    "# TODO: use gradient on whole image could speed up global process\n",
    "centers_guess_inds, amps = localize.find_peak_candidates(img_filtered, footprint, threshold=dog_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2a75a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  76,  14],\n",
       "       [  0, 127,  46],\n",
       "       [  0, 127,  65],\n",
       "       [  6,  58,  98],\n",
       "       [  8,  50,  26],\n",
       "       [ 17,  35,  69],\n",
       "       [ 19,   9,  40],\n",
       "       [ 21,  13,  12],\n",
       "       [ 22,  10, 127],\n",
       "       [ 26,  14, 116],\n",
       "       [ 34, 113, 119],\n",
       "       [ 39,  59, 116],\n",
       "       [ 43,  42, 105],\n",
       "       [ 44, 123,  59],\n",
       "       [ 44, 125,  29],\n",
       "       [ 48,   8,   0],\n",
       "       [ 49,  59,   0],\n",
       "       [ 51,  92, 123],\n",
       "       [ 58,  19, 121],\n",
       "       [ 59, 120,  93],\n",
       "       [ 61, 127,  93],\n",
       "       [ 63, 113,  79],\n",
       "       [ 74,  46, 125],\n",
       "       [ 76,  70,  58],\n",
       "       [ 78,  15,  31],\n",
       "       [ 78,  49,  73],\n",
       "       [ 90,  50, 122],\n",
       "       [ 91,  69,  69],\n",
       "       [102,  23,  89],\n",
       "       [127,  36, 127],\n",
       "       [127,  99, 127]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_guess_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffb44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'local maxis' at 0x7faadd063b20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72527a6f",
   "metadata": {},
   "source": [
    "### Merge peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9c809",
   "metadata": {},
   "source": [
    "Here there is not multiple local maxima per spot, so we will make some artificially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4393843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_peaks = len(centers_guess_inds)\n",
    "sampled_peaks = centers_guess_inds[np.random.choice(nb_peaks, size=int(1.5 * nb_peaks))]\n",
    "max_shift_z = 20\n",
    "max_shift_xy = 5\n",
    "nb_samples = len(sampled_peaks)\n",
    "z_shifts = np.random.choice(np.arange(-max_shift_z, max_shift_z+1), size=(nb_samples, 1))#.reshape((nb_samples, -1))\n",
    "xy_shifts = np.random.choice(np.arange(-max_shift_xy, max_shift_xy+1), size=(nb_samples, 2))\n",
    "peaks_shift = np.hstack([z_shifts, xy_shifts])\n",
    "shifted_samples = sampled_peaks + peaks_shift\n",
    "centers_guess_inds_duplic = np.vstack([centers_guess_inds, shifted_samples])\n",
    "\n",
    "# make sure new spots are not out of the image\n",
    "for i in range(3):\n",
    "    centers_guess_inds_duplic[centers_guess_inds_duplic[:, i] < 0, i] = 0\n",
    "    centers_guess_inds_duplic[centers_guess_inds_duplic[:, i] >= img.shape[i], i] = img.shape[i] -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'centers_guess_inds_duplic' at 0x7fdf8d6f2df0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers_guess_inds_duplic, name='centers_guess_inds_duplic', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe280e",
   "metadata": {},
   "source": [
    "#### Peaks merging functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50432308",
   "metadata": {},
   "source": [
    "The idea is to not loop through all peaks, and compute for each of them the distances with all other peaks, but instead build a kNN or radial distance graph.  \n",
    "Then we will compute distances along the z axis and in the xy plane, and use 2 distance thresholds to define peaks that are 'nearby'.  \n",
    "Then we cut the graph: we trim edges between non nearby peaks.  \n",
    "Then we merge peaks that are in the same connected cluster.   \n",
    "\n",
    "kNN graph may be problematic, as we may choose a too low k producing oversplit clusters, for instance if 2 pairs of points are in the same spot, but within each pair distances are smaller than across pairs, and we took k=1.  \n",
    "Thus we will use the radial distance method, taking the longest distance, the one along the z axis, to build an over connected graph that we will then cut with the bi-distance criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(source, target, method='xy_z_orthog', dist_fct='euclidian', tilt_vector=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : ndarray\n",
    "        Coordinates of the first set of points.\n",
    "    target : ndarray\n",
    "        Coordinates of the second set of points.\n",
    "    method : str\n",
    "        Method used to compute distances. If 'xyz', standard distances are computed considering all axes\n",
    "        simultaneously. If 'xy_z_orthog' 2 distances are computed, for the xy pkane and along the z axis \n",
    "        respectively. If 'xy_z_tilted' 2 distances are computed for the tilted plane and  its normal axis.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
    "    >>> target = np.array([[0, 0, 0], [-3, 0, 2], [0, 0, 10]])\n",
    "    >>> distance(source, target)\n",
    "        (array([0, 4, 0]), array([0., 2., 5.]))\n",
    "    >>> distance(source, target, dist_fct='L1')\n",
    "        (array([0, 4, 0]), array([0, 2, 7]))\n",
    "    \n",
    "    \"\"\"\n",
    "    if method == 'xyz':\n",
    "        if dist_fct == 'euclidian':\n",
    "            dist = np.sqrt(np.sum((source - target)**2, axis=1))\n",
    "        elif dist_fct == 'L1':\n",
    "            dist = np.sum((source - target), axis=1)\n",
    "        else:\n",
    "            dist = dist_fct(source, target, axis=1)\n",
    "        return dist\n",
    "    elif method == 'xy_z_orthog':\n",
    "        if dist_fct == 'euclidian':\n",
    "            dist_xy = np.sqrt(np.sum((source[:, 1:] - target[:, 1:])**2, axis=1))\n",
    "            dist_z = np.abs(source[:, 0] - target[:, 0])\n",
    "        elif dist_fct == 'L1':\n",
    "            dist_xy = np.sum(np.abs((source[:, 1:]  - target[:, 1:])), axis=1)\n",
    "            dist_z = np.abs(source[:, 0] - target[:, 0])\n",
    "        else:\n",
    "            dist_xy = dist_fct(source[:, 1:], target[:, 1:], axis=1)\n",
    "            dist_z = dist_fct(source[:, 0], target[:, 0])\n",
    "        return dist_z, dist_xy\n",
    "    elif method == 'xy_z_tilted':\n",
    "        raise NotImplementedError(\"Method 'xy_z_tilted' will be implemented soon\")\n",
    "\n",
    "\n",
    "def cut_graph_bidistance(dist_z, dist_xy, max_z, max_xy, pairs=None):\n",
    "    \"\"\"\n",
    "    Apply 2 thresholds on distances, along the z axis and in the xy plane,\n",
    "    to cut a graph of closest neighbors, i.e. to trim edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dist_z : array\n",
    "        Distances between nodes along the z axis.\n",
    "    dist_xy : array\n",
    "        Distances between nodes in the xy plane.\n",
    "    max_z : float\n",
    "        Distance threshold along the z axis.\n",
    "    max_xy : float\n",
    "        Distance threshold in the xy plane.\n",
    "    pairs : ndarray, optionnal\n",
    "        Array of pairs of nodes' indices defining the network, of shape nb_nodes x 2.\n",
    "        If not None, this array is filtered and returned in addition to the boolean filter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    select : array\n",
    "        Boolean filter used to select pairs of nodes considered as close to each other.\n",
    "    filtered_pairs : ndarray\n",
    "        Filtered array of pairs of nodes' indices that are close to each other.\n",
    "    \"\"\"\n",
    "\n",
    "    select = np.logical_and(dist_z <= max_z, dist_xy  <= max_xy)\n",
    "    if pairs is not None:\n",
    "        filtered_pairs = pairs[select, :]\n",
    "        return select, pairs\n",
    "    else:\n",
    "        return select\n",
    "\n",
    "\n",
    "def find_neighbors(pairs, n):\n",
    "    \"\"\"\n",
    "    Return the list of neighbors of a node in a network defined \n",
    "    by edges between pairs of nodes. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs : array_like\n",
    "        Pairs of nodes' id that define the network's edges.\n",
    "    n : int\n",
    "        The node for which we look for the neighbors.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    neigh : array_like\n",
    "        The indices of neighboring nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    left_neigh = pairs[pairs[:,1] == n, 0]\n",
    "    right_neigh = pairs[pairs[:,0] == n, 1]\n",
    "    neigh = np.hstack( (left_neigh, right_neigh) ).flatten()\n",
    "    \n",
    "    return neigh\n",
    "\n",
    "\n",
    "def neighbors_k_order(pairs, n, order):\n",
    "    \"\"\"\n",
    "    Return the list of up the kth neighbors of a node \n",
    "    in a network defined by edges between pairs of nodes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs : array_like\n",
    "        Pairs of nodes' id that define the network's edges.\n",
    "    n : int\n",
    "        The node for which we look for the neighbors.\n",
    "    order : int\n",
    "        Max order of neighbors.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    all_neigh : list\n",
    "        The list of lists of 1D array neighbor and the corresponding order\n",
    "    \n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> pairs = np.array([[0, 10],\n",
    "                        [0, 20],\n",
    "                        [0, 30],\n",
    "                        [10, 110],\n",
    "                        [10, 210],\n",
    "                        [10, 310],\n",
    "                        [20, 120],\n",
    "                        [20, 220],\n",
    "                        [20, 320],\n",
    "                        [30, 130],\n",
    "                        [30, 230],\n",
    "                        [30, 330],\n",
    "                        [10, 20],\n",
    "                        [20, 30],\n",
    "                        [30, 10],\n",
    "                        [310, 120],\n",
    "                        [320, 130],\n",
    "                        [330, 110]])\n",
    "    >>> neighbors_k_order(pairs, 0, 2)\n",
    "    [[array([0]), 0],\n",
    "     [array([10, 20, 30]), 1],\n",
    "     [array([110, 120, 130, 210, 220, 230, 310, 320, 330]), 2]]\n",
    "    \"\"\"\n",
    "    \n",
    "    # all_neigh stores all the unique neighbors and their oder\n",
    "    all_neigh = [[np.array([n]), 0]]\n",
    "    unique_neigh = np.array([n])\n",
    "    \n",
    "    for k in range(order):\n",
    "        # detected neighbor nodes at the previous order\n",
    "        last_neigh = all_neigh[k][0]\n",
    "        k_neigh = []\n",
    "        for node in last_neigh:\n",
    "            # aggregate arrays of neighbors for each previous order neighbor\n",
    "            neigh = np.unique(find_neighbors(pairs, node))\n",
    "            k_neigh.append(neigh)\n",
    "        # aggregate all unique kth order neighbors\n",
    "        if len(k_neigh) > 0:\n",
    "            k_unique_neigh = np.unique(np.concatenate(k_neigh, axis=0))\n",
    "            # select the kth order neighbors that have never been detected in previous orders\n",
    "            keep_neigh = np.in1d(k_unique_neigh, unique_neigh, invert=True)\n",
    "            k_unique_neigh = k_unique_neigh[keep_neigh]\n",
    "            # register the kth order unique neighbors along with their order\n",
    "            all_neigh.append([k_unique_neigh, k+1])\n",
    "            # update array of unique detected neighbors\n",
    "            unique_neigh = np.concatenate([unique_neigh, k_unique_neigh], axis=0)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return all_neigh\n",
    "\n",
    "\n",
    "def flatten_neighbors(all_neigh):\n",
    "    \"\"\"\n",
    "    Convert the list of neighbors 1D arrays with their order into\n",
    "    a single 1D array of neighbors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_neigh : list\n",
    "        The list of lists of 1D array neighbor and the corresponding order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flat_neigh : array_like\n",
    "        The indices of neighboring nodes.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> all_neigh = [[np.array([0]), 0],\n",
    "                     [np.array([10, 20, 30]), 1],\n",
    "                     [np.array([110, 120, 130, 210, 220, 230, 310, 320, 330]), 2]]\n",
    "    >>> flatten_neighbors(all_neigh)\n",
    "    array([  0,  10,  20,  30, 110, 120, 130, 210, 220, 230, 310, 320, 330])\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Code from the mosna library https://github.com/AlexCoul/mosna\n",
    "    \"\"\"\n",
    "    \n",
    "    list_neigh = []\n",
    "    for neigh, order in all_neigh:\n",
    "        list_neigh.append(neigh)\n",
    "    flat_neigh = np.concatenate(list_neigh, axis=0)\n",
    "\n",
    "    return flat_neigh\n",
    "\n",
    "\n",
    "def merge_nodes(coords, weight):\n",
    "    \"\"\"\n",
    "    Merge nodes coordinates by averaging them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : ndarray\n",
    "        Coordinates of nodes, array of shape nb_nodes x 3.\n",
    "    weight : array\n",
    "        Weight of nodes for coordinates averaging, \n",
    "        array fo shape nb_nodes x 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged_coords : ndarray\n",
    "        Coordinates of merged nodes.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> coords = np.array([[0, 0, 0], [2, -4, 8]])\n",
    "    >>> weight = np.array([1, 1]).reshape((len(coords), -1))\n",
    "    >>> merge_nodes(coords, weight)\n",
    "    array([ 1., -2.,  4.])\n",
    "    \"\"\"\n",
    "\n",
    "    tot_weight = weight.sum()\n",
    "    merged_coords = np.sum(coords * weight, axis=0) / weight.sum()\n",
    "    return merged_coords\n",
    "\n",
    "\n",
    "def merge_cluster_nodes(coords, pairs, weights=None, split_big_clust=False, cluster_size=None):\n",
    "    \"\"\"\n",
    "    Merge nodes that are in the same connected cluster, for all cluster in a graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : ndarray\n",
    "        Coordinates of nodes, array of shape nb_nodes x 3.\n",
    "    pairs : ndarray\n",
    "        Array of pairs of nodes' indices defining the network, of shape nb_nodes x 2.\n",
    "    weight : array\n",
    "        Weight of nodes for coordinates averaging. The image intensity at nodes\n",
    "        coordinates can be used as weights.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged_coords : ndarray\n",
    "        Coordinates of merged nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    nb_nodes = len(coords)\n",
    "    if weights is None:\n",
    "        weights = np.ones(nb_nodes)\n",
    "    # make list of nodes indices on which we will iterate\n",
    "    iter_nodes = np.arange(nb_nodes)\n",
    "    # variable storing new merged coordinates\n",
    "    merged_coords = []\n",
    "    # for each node, detect all its connected neighbors, even indirectly\n",
    "    for i in np.arange(nb_nodes):\n",
    "        # check if we have processed all nodes\n",
    "        if i >= len(iter_nodes):\n",
    "            break\n",
    "        else:\n",
    "            node_id = iter_nodes[i]\n",
    "            detected_neighbors = flatten_neighbors(neighbors_k_order(pairs, node_id, nb_nodes))\n",
    "            # delete these coordinates nodes indices to avoid reprocessing the same neighbors\n",
    "            select = np.isin(iter_nodes, detected_neighbors, assume_unique=True, invert=True)\n",
    "            iter_nodes = iter_nodes[select]\n",
    "            # merge nodes coordinates\n",
    "            if len(detected_neighbors) == 1:\n",
    "                merged_coords.append(coords[node_id])\n",
    "            else:\n",
    "                # detect if cluster likely contains multiple spots\n",
    "                if split_big_clust:\n",
    "                    if cluster_size is None:\n",
    "                        raise ValueError(\"`cluster_size` has to be given to split big clusters\")\n",
    "                    # work on it latter, for now use small distance thresholds\n",
    "                    # actually merge peaks\n",
    "                    cluster_coords = merge_nodes(coords[detected_neighbors], \n",
    "                                                 weights[detected_neighbors].reshape(-1, 1))\n",
    "                else:\n",
    "                    cluster_coords = merge_nodes(coords[detected_neighbors], \n",
    "                                                 weights[detected_neighbors].reshape(-1, 1))\n",
    "                merged_coords.append(cluster_coords)\n",
    "    merged_coords = np.vstack(merged_coords)\n",
    "    return merged_coords\n",
    "\n",
    "\n",
    "def filter_nearby_peaks(coords, max_z, max_xy, weight_img=None,\n",
    "                        split_big_clust=False, cluster_size=None):\n",
    "    \"\"\"\n",
    "    Merge nearby peaks in an image by building a radial distance graph and cutting it given\n",
    "    distance thresholds in the xy plane and along the z axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords : ndarray\n",
    "        Coordinates of nodes, array of shape nb_nodes x 3.\n",
    "    max_z : float\n",
    "        Distance threshold along the z axis.\n",
    "    max_xy : float\n",
    "        Distance threshold in the xy plane.\n",
    "    weight_img : ndarray\n",
    "        Image used to find peaks, now used to weight peaks coordinates during merge.\n",
    "        If None, equal weight is given to peaks coordinates.\n",
    "    split_big_clust : bool\n",
    "        If True, cluster big enough to contain multiple objects of interest (like spots)\n",
    "        are split into sub-clusters.\n",
    "    cluster_size : list | array\n",
    "        The threshold z and x/y size of clusters above which they are split.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    merged_coords : ndarray\n",
    "        The coordinates of merged peaks.\n",
    "    \"\"\"\n",
    "\n",
    "    # build the radial distance network using the bigest radius: max distance along z axis\n",
    "    pairs = ty.build_rdn(coords=coords, r=max_z)\n",
    "    source = coords[pairs[:, 0]]\n",
    "    target = coords[pairs[:, 1]]\n",
    "    # compute the 2 distances arrays\n",
    "    dist_z, dist_xy = compute_distances(source, target)\n",
    "    # perform grph cut from the 2 distance thresholds\n",
    "    _, pairs = cut_graph_bidistance(dist_z, dist_xy, max_z, max_xy, pairs=pairs)\n",
    "\n",
    "    if weight_img is not None:\n",
    "        # need ravel_multi_index to get pixel values of weight_img at several 3D coordinates\n",
    "        amplitudes_id = np.ravel_multi_index(coords.transpose(), weight_img.shape)\n",
    "        weights = weight_img.ravel()[amplitudes_id]\n",
    "    else:\n",
    "        weights = None  # array of ones will be generated in merge_cluster_nodes\n",
    "    # merge nearby nodes coordinates\n",
    "    merged_coords = merge_cluster_nodes(coords, pairs, weights,\n",
    "                                        split_big_clust=split_big_clust, \n",
    "                                        cluster_size=cluster_size)\n",
    "\n",
    "    return merged_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c962c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_z = 10\n",
    "max_xy = 3\n",
    "pairs = ty.build_rdn(coords=centers_guess_inds_duplic, r=max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91b8949d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb5399a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_guess_inds_duplic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce723c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = centers_guess_inds_duplic[pairs[:, 0]]\n",
    "target = centers_guess_inds_duplic[pairs[:, 1]]\n",
    "\n",
    "dist_z, dist_xy = compute_distances(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db6460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 2)\n"
     ]
    }
   ],
   "source": [
    "select, pairs = cut_graph_bidistance(dist_z, dist_xy, max_z, max_xy, pairs=pairs)\n",
    "print(pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35056344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n",
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers_guess_inds_duplic, name='centers_guess_inds_duplic', blending='additive', size=3, face_color='g')\n",
    "\n",
    "napari_coords = ty.convert_nodes_tys_to_nap(centers_guess_inds_duplic)\n",
    "# napari_edges = ty.convert_edges_tys_to_nap(centers_guess_inds_duplic, pairs)\n",
    "\n",
    "def make_annotation_dict(coords, pairs=None,\n",
    "                         nodes_class=None,\n",
    "                         nodes_class_color_mapper=None,\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Create a dictionnary of annotations from tysserand network objects.\n",
    "    \"\"\"\n",
    "\n",
    "    annotations = {}\n",
    "    new_nodes = ty.convert_nodes_tys_to_nap(coords)\n",
    "    annotations['nodes_coords'] = new_nodes\n",
    "    if nodes_class is not None:\n",
    "        annotations['nodes_class'] = nodes_class\n",
    "    if nodes_class_color_mapper is not None:\n",
    "        annotations['nodes_class_color_mapper'] = nodes_class_color_mapper\n",
    "    if pairs is not None:\n",
    "        annotations['edges_coords'] = pairs # convert_edges_tys_to_nap(new_nodes, pairs)\n",
    "    return annotations\n",
    "\n",
    "# annotations = make_annotation_dict(\n",
    "#     napari_coords, pairs=napari_edges,\n",
    "# )\n",
    "annotations = ty.make_annotation_dict(\n",
    "    napari_coords, pairs=pairs,\n",
    ")\n",
    "ty.add_annotations(viewer, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "198ec1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          76.          14.        ]\n",
      " [  0.         125.14835165  63.14835165]\n",
      " [  8.          50.          26.        ]\n",
      " [ 20.35775862   8.74568966  41.61206897]\n",
      " [ 29.22154964  12.18644068 118.56416465]\n",
      " [ 39.          59.         116.        ]\n",
      " [ 44.         123.          59.        ]\n",
      " [ 47.73         5.57         1.08      ]\n",
      " [ 49.26898048  94.62472885 122.82212581]\n",
      " [ 62.46956522 124.83913043  91.95652174]\n",
      " [ 74.          47.88811189 124.62237762]\n",
      " [ 74.98275862  13.47413793  31.25      ]\n",
      " [ 92.0620438   50.41240876 120.35036496]\n",
      " [102.38589212  23.          90.92946058]\n",
      " [125.278125   100.0390625  125.346875  ]\n",
      " [ 76.          23.         120.        ]\n",
      " [ 65.84419263 115.50424929  78.35410765]\n",
      " [ 32.53017241   8.06034483   2.34913793]\n",
      " [124.61408451  36.69295775 127.        ]\n",
      " [ 75.18478261  72.2826087   61.01086957]\n",
      " [ 59.          55.         120.        ]\n",
      " [ 49.         112.         119.        ]]\n",
      "(22, 3)\n"
     ]
    }
   ],
   "source": [
    "# need ravel_multi_index to get pixel values of img at several 3D coordinates\n",
    "amps_id = np.ravel_multi_index(centers_guess_inds_duplic.transpose(), img.shape)\n",
    "amps = img.ravel()[amps_id]\n",
    "\n",
    "merged_coords = merge_cluster_nodes(centers_guess_inds_duplic, pairs, weights=amps)\n",
    "print(merged_coords)\n",
    "print(merged_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function doesn't output pairs, run cells above to get it\n",
    "# merged_coords = filter_nearby_peaks(centers_guess_inds_duplic, max_z=15, max_xy=4, weight_img=img)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers_guess_inds_duplic, name='centers_guess_inds_duplic', blending='additive', size=3, face_color='g')\n",
    "viewer.add_points(merged_coords, name='merged_coords', blending='additive', size=3, face_color='b')\n",
    "\n",
    "napari_coords = ty.convert_nodes_tys_to_nap(centers_guess_inds_duplic)\n",
    "annotations = ty.make_annotation_dict(\n",
    "    napari_coords, pairs=pairs,\n",
    ")\n",
    "ty.add_edges(viewer, annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e1451",
   "metadata": {},
   "source": [
    "### Try Peter's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d40585",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_z = 10\n",
    "max_xy = 3\n",
    "\n",
    "# need ravel_multi_index to get pixel values of img at several 3D coordinates\n",
    "amps_id = np.ravel_multi_index(centers_guess_inds_duplic.transpose(), img.shape)\n",
    "amps = img.ravel()[amps_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 points separated by dxy > 3 and dz > 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "centers_merged, inds_comb = localize.filter_nearby_peaks(centers_guess_inds_duplic, max_xy, max_z, weights=amps,\n",
    "                                                         mode=\"average\")\n",
    "\n",
    "amps_merged = amps[inds_comb]\n",
    "print(\"Found %d points separated by dxy > %0.5g and dz > %0.5g\" %\n",
    "      (len(centers_merged), max_xy, max_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aac3ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'centers_merged' at 0x7fdf7f523af0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers_guess_inds_duplic, name='centers_guess_inds_duplic', blending='additive', size=3, face_color='g')\n",
    "viewer.add_points(centers_merged, name='centers_merged', blending='additive', size=3, face_color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5be8c",
   "metadata": {},
   "source": [
    "### Fit gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baef11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_coordinates(centers, sizes, max_coords_val, min_sizes, return_sizes=True):\n",
    "    \"\"\"\n",
    "    Make pairs of (z, y, x) coordinates defining an ROI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : ndarray, dtype int\n",
    "        Centers of future ROIs, a Nx3 array.\n",
    "    sizes : array or list\n",
    "        Size of ROIs in each dimensions.\n",
    "    max_coords_val : array or list\n",
    "        Maximum value of coordinates in each dimension,\n",
    "        typically the original image shape - 1.\n",
    "    min_sizes : array or list\n",
    "        Minimum size of ROIs in each dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    roi_coords : ndarray\n",
    "        Pairs of point coordinates, a 2xNx3 array.\n",
    "    roi_coords : ndarray\n",
    "        Shape of each ROI, Nx3 array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make raw coordinates\n",
    "    min_coords = centers - sizes / 2\n",
    "    max_coords = centers + sizes / 2\n",
    "    coords = np.stack([min_coords, max_coords]).astype(int)\n",
    "    # clean min and max values of coordinates\n",
    "    coords[coords < 0] = 0\n",
    "    for i in range(3):\n",
    "        coords[1, coords[1, :, i] > max_coords_val[i], i] = max_coords_val[i]\n",
    "    # delete small ROIs\n",
    "    roi_sizes = coords[1, :, :] - coords[0, :, :]\n",
    "    select = ~np.any([roi_sizes[:, i] <= min_sizes[i] for i in range(3)], axis=0)\n",
    "    coords = coords[:, select, :]\n",
    "    # swap axes for latter convenience\n",
    "    roi_coords = np.swapaxes(coords, 0, 1)\n",
    "    \n",
    "    if return_sizes:\n",
    "        roi_sizes = roi_sizes[select, :]\n",
    "        return roi_coords, roi_sizes\n",
    "    else:\n",
    "        return roi_coords\n",
    "\n",
    "    \n",
    "def extract_ROI(img, coords):\n",
    "    \"\"\"\n",
    "    Extract a portion of an image given by the coordinates of 2 points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : ndarray, dimension 3\n",
    "        The i;age from which the ROI is extracted.\n",
    "    coords : ndarry, shape (2, 3)\n",
    "        The 2 coordinates of the 3 dimensional points at the corner of the ROI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    roi : ndarray\n",
    "        A region of interest of the original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    z0, y0, x0 = coords[0]\n",
    "    z1, y1, x1 = coords[1]\n",
    "    roi = img[z0:z1, y0:y1, x0:x1]\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660016af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centers = centers_guess_inds\n",
    "# size = 2 * np.array([sz, sy, sx])\n",
    "# min_coords = centers - size / 2\n",
    "# max_coords = centers + size / 2\n",
    "# coords = np.stack([min_coords, max_coords]).astype(int)\n",
    "# max_coords_val = np.array(img.shape) - 1\n",
    "# coords[coords < 0] = 0\n",
    "# for i in range(3):\n",
    "#     coords[1, coords[1, :, i] > max_coords_val[i], i] = max_coords_val[i]\n",
    "# min_sizes = [sz, sy, sx]\n",
    "# select = ~np.any([roi_sizes[:, i] <= min_sizes[i] for i in range(3)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_sizes = coords[1, :, :] - coords[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e59055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98dec31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_roi_sizes = np.array([1.3, 1, 1]) * np.array([sz, sy, sx])\n",
    "fit_roi_sizes = 2* np.array([sz, sy, sx])\n",
    "# min_fit_roi_sizes = fit_roi_sizes * 0.7\n",
    "min_fit_roi_sizes = fit_roi_sizes * 0.5\n",
    "\n",
    "roi_coords, roi_sizes = get_roi_coordinates(\n",
    "    centers = centers_guess_inds, \n",
    "    sizes = fit_roi_sizes, \n",
    "    max_coords_val = np.array(img.shape) - 1, \n",
    "    min_sizes = min_fit_roi_sizes,\n",
    ")\n",
    "nb_rois = roi_coords.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d14beadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "viewer.add_points(roi_coords[:, 0, :], name='ROI start', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(roi_coords[:, 1, :], name='ROI end', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818ddbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# # all_rois = np.stack(extract_ROI(img, roi_coords[i]) for i in range(nb_rois))\n",
    "# # viewer.add_image(all_rois, name='all rois')\n",
    "# for i in range(nb_rois):\n",
    "#     roi = extract_ROI(img, roi_coords[i])\n",
    "#     viewer.add_image(roi, name=f'roi {i}', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ddd99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# im_fitted = img_high_pass - img_low_pass\n",
    "im_fitted = img\n",
    "\n",
    "roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "roi_gauss = extract_ROI(img_high_pass, roi_coords[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e4b57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'roi gauss' at 0x7faadce93340>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(roi, name='roi')\n",
    "viewer.add_image(roi_gauss, name='roi gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1501809",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_guess = (roi_sizes / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb79ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = np.array([\n",
    "    amps[i], \n",
    "    centers_guess[i, 2],\n",
    "    centers_guess[i, 1],\n",
    "    centers_guess[i, 0],\n",
    "    sigma_xy, \n",
    "    sigma_z, \n",
    "    roi.min(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414b06a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_params': array([ 74.69952656,   5.02998613,   4.76409973,   7.97728355,\n",
       "          1.70918589,   5.30709257, 107.47698163]),\n",
       " 'chi_squared': 69.48408763251489,\n",
       " 'covariance': array([[ 2.13626096e+00, -2.25476371e-06,  3.60775456e-06,\n",
       "          6.90209117e-03, -2.16276125e-02, -7.84538106e-02,\n",
       "          4.98045363e-02],\n",
       "        [-2.25476371e-06,  8.53925344e-04,  3.01570789e-08,\n",
       "         -8.17091106e-07, -1.86392270e-06, -9.33633663e-06,\n",
       "          5.68913670e-05],\n",
       "        [ 3.60775456e-06,  3.01570789e-08,  8.53365821e-04,\n",
       "         -3.92916937e-07, -1.02500817e-06, -4.48959090e-06,\n",
       "          2.73575144e-05],\n",
       "        [ 6.90209117e-03, -8.17091106e-07, -3.92916937e-07,\n",
       "          9.10347028e-03,  4.53574780e-05, -1.46538606e-03,\n",
       "         -7.88318688e-04],\n",
       "        [-2.16276125e-02, -1.86392270e-06, -1.02500817e-06,\n",
       "          4.53574780e-05,  6.11379772e-04,  5.18268625e-04,\n",
       "         -3.15809205e-03],\n",
       "        [-7.84538106e-02, -9.33633663e-06, -4.48959090e-06,\n",
       "         -1.46538606e-03,  5.18268625e-04,  1.22994484e-02,\n",
       "         -9.00757405e-03],\n",
       "        [ 4.98045363e-02,  5.68913670e-05,  2.73575144e-05,\n",
       "         -7.88318688e-04, -3.15809205e-03, -9.00757405e-03,\n",
       "          5.48880381e-02]]),\n",
       " 'init_params': array([ 6.94657208,  5.        ,  5.        , 13.        ,  2.12314225,\n",
       "         8.492569  , 80.        ]),\n",
       " 'fixed_params': [False, False, False, False, False, False, False],\n",
       " 'bounds': [[0, 0, 0, 0, 0, 0, -inf], [inf, 9, 9, 25, inf, inf, inf]],\n",
       " 'cost': 90086.11961555555,\n",
       " 'optimality': 6.205495467891146,\n",
       " 'nfev': 17,\n",
       " 'njev': 16,\n",
       " 'status': 2,\n",
       " 'success': True,\n",
       " 'message': '`ftol` termination condition is satisfied.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = 0.\n",
    "\n",
    "fit_results = localize.fit_gauss_roi(\n",
    "    roi, \n",
    "    (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "    init_params,\n",
    ")\n",
    "fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1d43acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rois = [extract_ROI(im_fitted, roi_coords[i]) for i in range(nb_rois)]\n",
    "# coords_rois = [localize.get_coords(roi_sizes[i], drs=[1, 1, 1]) for i in range(nb_rois)]\n",
    "coords_rois = [coords_rois[:, :, i] for i in range(3)]\n",
    "init_params = np.array([[\n",
    "        amps[i], \n",
    "        centers_guess[i, 2],\n",
    "        centers_guess[i, 1],\n",
    "        centers_guess[i, 0],\n",
    "        sigma_xy, \n",
    "        sigma_z, \n",
    "        roi.min(),\n",
    "    ] for i in range(nb_rois)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6eaf2795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_rois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10a10f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  26],\n",
       "       [  0,  28],\n",
       "       [  0,  37],\n",
       "       [  0,  39],\n",
       "       [  1,  41],\n",
       "       [  6,  46],\n",
       "       [ 14,  54],\n",
       "       [ 19,  59],\n",
       "       [ 23,  63],\n",
       "       [ 24,  64],\n",
       "       [ 24,  64],\n",
       "       [ 31,  71],\n",
       "       [ 38,  78],\n",
       "       [ 39,  79],\n",
       "       [ 43,  83],\n",
       "       [ 54,  94],\n",
       "       [ 56,  96],\n",
       "       [ 58,  98],\n",
       "       [ 58,  98],\n",
       "       [ 70, 110],\n",
       "       [ 71, 111],\n",
       "       [ 82, 122]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_rois[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da8d42d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "status = -1, message = b'no kernel image is available for execution on the device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb Cell 60'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=0'>1</a>\u001b[0m fit_results \u001b[39m=\u001b[39m localize\u001b[39m.\u001b[39;49mfit_gauss_rois(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=1'>2</a>\u001b[0m     img_rois, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=2'>3</a>\u001b[0m     coords_rois, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=3'>4</a>\u001b[0m     init_params,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000196?line=5'>6</a>\u001b[0m fit_results\n",
      "File \u001b[0;32m~/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py:772\u001b[0m, in \u001b[0;36mfit_gauss_rois\u001b[0;34m(img_rois, coords_rois, init_params, max_number_iterations, sf, dc, angles, estimator, model, fixed_params, use_gpu)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=769'>770</a>\u001b[0m params_to_fit \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mnot\u001b[39;00m fp \u001b[39mfor\u001b[39;00m fp \u001b[39min\u001b[39;00m fixed_params], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=770'>771</a>\u001b[0m \u001b[39m# do fitting\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=771'>772</a>\u001b[0m fit_params, fit_states, chi_sqrs, niters, fit_t \u001b[39m=\u001b[39m gf\u001b[39m.\u001b[39;49mfit(data, \u001b[39mNone\u001b[39;49;00m, model_id, init_params,\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=772'>773</a>\u001b[0m                                                          max_number_iterations\u001b[39m=\u001b[39;49mmax_number_iterations,\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=773'>774</a>\u001b[0m                                                          estimator_id\u001b[39m=\u001b[39;49mest_id,\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=774'>775</a>\u001b[0m                                                          parameters_to_fit\u001b[39m=\u001b[39;49mparams_to_fit,\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=775'>776</a>\u001b[0m                                                          user_info\u001b[39m=\u001b[39;49muser_info)\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=777'>778</a>\u001b[0m \u001b[39m# correct sigmas in case negative\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py?line=778'>779</a>\u001b[0m fit_params[:, \u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(fit_params[:, \u001b[39m4\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py:209\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(data, weights, model_id, initial_parameters, tolerance, max_number_iterations, parameters_to_fit, estimator_id, user_info)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=205'>206</a>\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m Status\u001b[39m.\u001b[39mOk:\n\u001b[1;32m    <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=206'>207</a>\u001b[0m     \u001b[39m# get error from last error and raise runtime error\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=207'>208</a>\u001b[0m     error_message \u001b[39m=\u001b[39m error_func()\n\u001b[0;32m--> <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=208'>209</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mstatus = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, message = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(status, error_message))\n\u001b[1;32m    <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=210'>211</a>\u001b[0m \u001b[39m# return output values\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/pygpufit/gpufit.py?line=211'>212</a>\u001b[0m \u001b[39mreturn\u001b[39;00m parameters, states, chi_squares, number_iterations, t1 \u001b[39m-\u001b[39m t0\n",
      "\u001b[0;31mRuntimeError\u001b[0m: status = -1, message = b'no kernel image is available for execution on the device'"
     ]
    }
   ],
   "source": [
    "fit_results = localize.fit_gauss_rois(\n",
    "    img_rois, \n",
    "    coords_rois, \n",
    "    init_params,\n",
    ")\n",
    "fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2568b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = fit_results['fit_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ce1193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'fitted center' at 0x7f92b17f13d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(roi, name='roi')\n",
    "viewer.add_image(roi_gauss, name='roi gauss')\n",
    "viewer.add_points([center_z, center_y, center_x], name='fitted center', blending='additive', size=2, face_color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using img_high_pass or img_filtered gives really bad results\n",
    "# # I'd like to understand why fitted centered are all shifted\n",
    "# im_fitted = img #img_high_pass - img_low_pass # img\n",
    "\n",
    "# fit_results_rois = np.zeros((nb_rois, 8))\n",
    "# for i in range(nb_rois):\n",
    "#     # extract ROI\n",
    "#     roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "#     # fit gaussian in ROI\n",
    "#     init_params = np.array([\n",
    "#         amps[i], \n",
    "#         centers_guess[i, 2],\n",
    "#         centers_guess[i, 1],\n",
    "#         centers_guess[i, 0],\n",
    "#         sigma_xy, \n",
    "#         sigma_z, \n",
    "#         roi.min(),\n",
    "#     ])\n",
    "#     fit_results_roi = localize.fit_gauss_roi(\n",
    "#         roi, \n",
    "#         (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "#         init_params,\n",
    "#     )\n",
    "#     # amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset\n",
    "#     fit_results_rois[i, :7] = fit_results_roi['fit_params']\n",
    "#     fit_results_rois[i, 7] = fit_results_roi['chi_squared']\n",
    "# # add origin coordinates of each ROI\n",
    "# centers = fit_results_rois[:, 1:4] + roi_coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646394d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using img_high_pass or img_filtered gives really bad results\n",
    "# I'd like to understand why fitted centered are all shifted\n",
    "im_fitted = img #img_high_pass - img_low_pass # img\n",
    "\n",
    "amplitudes = []\n",
    "centers = []\n",
    "sigmas = []\n",
    "chi_squareds = []\n",
    "all_res = []\n",
    "for i in range(nb_rois):\n",
    "    # extract ROI\n",
    "    roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "    # fit gaussian in ROI\n",
    "    init_params = np.array([\n",
    "        amps[i], \n",
    "        centers_guess[i, 2],\n",
    "        centers_guess[i, 1],\n",
    "        centers_guess[i, 0],\n",
    "        sigma_xy, \n",
    "        sigma_z, \n",
    "        roi.min(),\n",
    "    ])\n",
    "    fit_results = localize.fit_gauss_roi(\n",
    "        roi, \n",
    "        (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "        init_params,\n",
    "        fixed_params=np.full_like(init_params, False),\n",
    "    )\n",
    "    amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = fit_results['fit_params']\n",
    "    amplitudes.append(amplitude)\n",
    "    centers.append([center_z, center_y, center_x])\n",
    "    sigmas.append([sigma_xy, sigma_z])\n",
    "    chi_squareds.append(fit_results['chi_squared'])\n",
    "    all_res.append(fit_results['fit_params'])\n",
    "#     print(fit_results)\n",
    "# add origin coordinates of each ROI\n",
    "centers = np.array(centers) + roi_coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_res)[:,-4:]\n",
    "# np.array(all_res)[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87410067",
   "metadata": {},
   "source": [
    "Fits only amplitude if ROI is too small, covarianc is a matrix of nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color='g')\n",
    "# viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color=chi_squareds, face_colormap=cmap); # napari colormap doesn't work\n",
    "# viewer.add_points(centers, name='fitted centers chi squared', blending='additive', size=3, face_color=chi_colors)\n",
    "# viewer.add_points(centers, name='fitted centers sigma xy', blending='additive', size=3, face_color=sigma_xy_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089250b6",
   "metadata": {},
   "source": [
    "Some blobs look like real spot blobs but are actually non spot blobs, they look simimlar becaus of the DoG kernel.  \n",
    "In these blobs the diff between center from peak max and gaussian fit is noticeable.  \n",
    "For real spot blobs, sometimes the peak max seems to provide more accurarte estimation of center's coordinates, but on the real image we observe that the gaussian fit is the most accurate method with small enough ROI.\n",
    "But with too small ROI there is no real fitting, and with too big ROI one center can shift due to near spot. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e623183",
   "metadata": {},
   "source": [
    "Now need to filter fitted spots:\n",
    "  - goodness of fit\n",
    "  - ratio sigma_z / sigma_xy\n",
    "  - maximum distance between guess value and fit value\n",
    "  - range of sigmas\n",
    "  - ramge of intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from napari.utils.colormaps.colormap_utils import vispy_or_mpl_colormap\n",
    "# cmap = vispy_or_mpl_colormap('plasma')\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('plasma')\n",
    "\n",
    "chi_squareds = np.array(chi_squareds)\n",
    "norm = mpl.colors.Normalize(vmin=chi_squareds.min(), vmax=chi_squareds.max())\n",
    "chi_colors = [cmap(norm(x)) for x in chi_squareds]\n",
    "\n",
    "sigmas = np.array(sigmas)\n",
    "sigma_z_xy_ratios = sigmas[:, 0] / sigmas[:, 1]\n",
    "# norm = mpl.colors.Normalize(vmin=sigmas[:, 0].min(), vmax=sigmas[:, 0].max())\n",
    "# sigma_xy_colors = [cmap(norm(x)) for x in sigmas[:, 0]]\n",
    "norm = mpl.colors.Normalize(vmin=sigma_z_xy_ratios.min(), vmax=sigma_z_xy_ratios.max())\n",
    "sigma_ratios_colors = [cmap(norm(x)) for x in sigma_z_xy_ratios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48034964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_z_xy_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigma_z_xy_ratios);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sigmas[:, 0], sigmas[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81764f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "# viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color='g')\n",
    "# viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color=chi_squareds, face_colormap=cmap); # napari colormap doesn't work\n",
    "# viewer.add_points(centers, name='fitted centers chi squared', blending='additive', size=3, face_color=chi_colors)\n",
    "viewer.add_points(centers, name='fitted centers sigma ratios', blending='additive', size=3, face_color=sigma_ratios_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020f794",
   "metadata": {},
   "source": [
    "### Radial spot finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "# im_fitted = img_high_pass - img_low_pass\n",
    "im_fitted = img\n",
    "\n",
    "roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "roi_gauss = extract_ROI(img_high_pass, roi_coords[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x, center_y, center_z = localize.localize3d(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((center_z, center_y, center_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(roi, name='roi')\n",
    "viewer.add_image(roi_gauss, name='roi gauss')\n",
    "viewer.add_points(centers_guess[i], name='guessed center', blending='additive', size=2, face_color='r')\n",
    "viewer.add_points(np.hstack((center_z, center_y, center_x)), name='fitted center', blending='additive', size=2, face_color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb55579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using img_high_pass or img_filtered gives really bad results\n",
    "# I'd like to understand why fitted centered are all shifted\n",
    "# im_fitted = img\n",
    "im_fitted = img_high_pass\n",
    "# im_fitted = img_high_pass - img_low_pass\n",
    "\n",
    "centers = np.zeros((nb_rois, 3))\n",
    "for i in range(nb_rois):\n",
    "    # extract ROI\n",
    "    roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "    # radial method fitting\n",
    "#     center_x, center_y, center_z = localize.localize3d(roi)\n",
    "    centers[i, :] = np.hstack(localize.localize3d(roi))[::-1]\n",
    "#     print(fit_results)\n",
    "# reverse axes from \n",
    "# add origin coordinates of each ROI\n",
    "centers = centers + roi_coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fe585",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737b677",
   "metadata": {},
   "source": [
    "Still not perfect, probably need the RANSAC version of it.  \n",
    "But how do we define the most accurate method if it's not with gaussian fitting?..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca8375",
   "metadata": {},
   "source": [
    "## Tiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc10632",
   "metadata": {},
   "source": [
    "Considering a good enough spot finding method, run it on several tiles and merge results\n",
    "One solution could be using Dask [map_overlap](https://docs.dask.org/en/latest/generated/dask.array.map_overlap.html)  \n",
    "but we run computation on extra areas and we need to manage how to merge results in the overlaping ares.  \n",
    "On the pther hand, the `get_roi_coordinates` has a `min_sizes` argument that we can use so with a given overlap we only keep once spots ROIs, either in one tile or the neighbooring one.  \n",
    "To do so, `overlap = min_sizes - 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c98ef1f",
   "metadata": {},
   "source": [
    "### Make coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_split_overlap(seq_size, chunk_size, overlap=0):\n",
    "    # TODO: improve accuracy of computed sequences of indices \n",
    "    if chunk_size < 1 or overlap < 0:\n",
    "        raise ValueError('check chunk_size > 1 and overlap > 0')\n",
    "\n",
    "    if chunk_size >= seq_size:\n",
    "        return [0, seq_size]\n",
    "\n",
    "    for i in range(0, seq_size - overlap, chunk_size - overlap):\n",
    "        pass\n",
    "\n",
    "\n",
    "def make_tiles_coordinates(total_size, tile_size, overlap):\n",
    "    \"\"\"\n",
    "    Make a list of pairs of coordinates that define overlaping tiles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    total_size : array | list | tuple\n",
    "        The size of the original big image from which tiles are extracted.\n",
    "    tile_size : int | array\n",
    "        The size of tiles' dimensions without overlap. Dimensions are of equal \n",
    "        size if int, else each dimension size is given by the array.\n",
    "    overlap : int | array | list | tuple\n",
    "        Overlap between neighbooring tiles. Overlaps are of equal \n",
    "        size if int, else each overlap size is given by the iterable.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tiles_coordinates : ndarray\n",
    "        Pairs of coordinates, dim (nb_tiles, 2, dim_image)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> make_tiles_coordinates(total_size=(5, 5), tile_size=(2, 2), overlap=1)\n",
    "    array([[[0, 0], [2, 2]],\n",
    "           [[0, 2], [2, 4]],\n",
    "           [[2, 0], [4, 2]],\n",
    "           [[2, 2], [4, 4]]])\n",
    "    \"\"\"\n",
    "    pass   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1161969",
   "metadata": {},
   "outputs": [],
   "source": [
    "localize.get_coords([5, 5], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 10\n",
    "data = np.arange(total_size)\n",
    "chunk_size = 5\n",
    "overlap = 3\n",
    "\n",
    "np.arange(start=0, stop=total_size, step=chunk_size)\n",
    "\n",
    "# coords = np.array(list(gen_split_overlap(total_size, chunk_size, overlap)))\n",
    "# coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3de1c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(data[coords[0, 0]: coords[0, 1]])\n",
    "print(data[coords[1, 0]: coords[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97748843",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiler = Tiler(\n",
    "    data_shape=(5, 5),\n",
    "    tile_shape=(2, 2),\n",
    "    overlap=1,\n",
    "    channel_dimension=None,\n",
    "    mode='irregular',\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    print(tiler.get_tile_bbox(tile_id=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b459e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.arange(100).reshape(10, 10)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiler = Tiler(\n",
    "    data_shape=image.shape,\n",
    "    tile_shape=(5, 5),\n",
    "    overlap=1,\n",
    "    channel_dimension=None,\n",
    "    mode='irregular',\n",
    ")\n",
    "for tile_id, tile in tiler.iterate(image):\n",
    "    coords = tiler.get_tile_bbox(tile_id=tile_id)\n",
    "    print(coords)\n",
    "    print(tile)\n",
    "    print()\n",
    "    print(image[coords[0][0]: coords[1][0], coords[0][1]: coords[1][1]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b146bf",
   "metadata": {},
   "source": [
    "We have now a way to get coordinatesof overlapping tiles, now we need to make a function that detect spots per ROI, and one that merges the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd31413",
   "metadata": {},
   "source": [
    "### Functionalize spot detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a09a0",
   "metadata": {},
   "source": [
    "#### check Dask behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "\n",
    "client = Client(n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703bb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_function_1(arg=None):\n",
    "    if arg is None:\n",
    "        return \"sub_function_1\"\n",
    "    else:\n",
    "        return \"sub_function_1, arg:\", arg\n",
    "\n",
    "def sub_function_2(arg):\n",
    "    print(\"sub_function_2, arg:\", arg)\n",
    "\n",
    "def global_function(fct, fct_arg=None):\n",
    "    print(\"executed\")\n",
    "    if fct_arg is None:\n",
    "        return fct()\n",
    "    else:\n",
    "        return fct(**fct_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ea374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = delayed(global_function)(sub_function_1, {fct_arg:'Un argument!'})\n",
    "# x = delayed(global_function)(4)\n",
    "# print(x)\n",
    "# print(x.compute())\n",
    "\n",
    "x = delayed(global_function)(sub_function_1, {'arg': 4})\n",
    "print(x)\n",
    "print(x.compute())\n",
    "\n",
    "x = delayed(global_function)(sub_function_1)\n",
    "print(x)\n",
    "print(x.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e82e4",
   "metadata": {},
   "source": [
    "#### base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of spots in pixels\n",
    "sx = sy = 5\n",
    "sz = 20\n",
    "# FWHM = 2.355 x sigma\n",
    "sigma_xy = sx / 2.355\n",
    "sigma_z = sz / 2.355\n",
    "# to reproduce LoG with Dog we need sigma_big = 1.6 * sigma_small\n",
    "sigma_xy_small = sigma_xy / 1.6**(1/2)\n",
    "sigma_xy_large = sigma_xy * 1.6**(1/2)\n",
    "sigma_z_small = sigma_z / 1.6**(1/2)\n",
    "sigma_z_large = sigma_z * 1.6**(1/2)\n",
    "\n",
    "\n",
    "\n",
    "def get_roi_coordinates(centers, sizes, max_coords_val, min_sizes, return_sizes=False):\n",
    "    \"\"\"\n",
    "    Make pairs of (z, y, x) coordinates defining an ROI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : ndarray, dtype int\n",
    "        Centers of future ROIs, a Nx3 array.\n",
    "    sizes : array or list\n",
    "        Size of ROIs in each dimensions.\n",
    "    max_coords_val : array or list\n",
    "        Maximum value of coordinates in each dimension,\n",
    "        typically the original image shape - 1.\n",
    "    min_sizes : array or list\n",
    "        Minimum size of ROIs in each dimension.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    roi_coords : ndarray\n",
    "        Pairs of point coordinates, a 2xNx3 array.\n",
    "    roi_coords : ndarray\n",
    "        Shape of each ROI, Nx3 array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make raw coordinates\n",
    "    min_coords = centers - sizes / 2\n",
    "    max_coords = centers + sizes / 2\n",
    "    coords = np.stack([min_coords, max_coords]).astype(int)\n",
    "    # clean min and max values of coordinates\n",
    "    coords[coords < 0] = 0\n",
    "    for i in range(3):\n",
    "        coords[1, coords[1, :, i] > max_coords_val[i], i] = max_coords_val[i]\n",
    "    # delete small ROIs\n",
    "    roi_sizes = coords[1, :, :] - coords[0, :, :]\n",
    "    select = ~np.any([roi_sizes[:, i] < min_sizes[i] for i in range(3)], axis=0)\n",
    "    coords = coords[:, select, :]\n",
    "    # swap axes for latter convenience\n",
    "    roi_coords = np.swapaxes(coords, 0, 1)\n",
    "    \n",
    "    if return_sizes:\n",
    "        roi_sizes = roi_sizes[select, :]\n",
    "        return roi_coords, roi_sizes\n",
    "    else:\n",
    "        return roi_coords\n",
    "\n",
    "    \n",
    "def extract_ROI(img, coords):\n",
    "    \"\"\"\n",
    "    Extract a portion of an image given by the coordinates of 2 points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : ndarray, dimension 3\n",
    "        The i;age from which the ROI is extracted.\n",
    "    coords : ndarry, shape (2, 3)\n",
    "        The 2 coordinates of the 3 dimensional points at the corner of the ROI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    roi : ndarray\n",
    "        A region of interest of the original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    z0, y0, x0 = coords[0]\n",
    "    z1, y1, x1 = coords[1]\n",
    "    roi = img[z0:z1, y0:y1, x0:x1]\n",
    "    return roi\n",
    "\n",
    "\n",
    "def detect_blob_dog(img, sigma_xy_small, sigma_xy_large, \n",
    "                    sigma_z_small, sigma_z_large, dog_thresh,\n",
    "                    min_separations, pixel_sizes,\n",
    "                    sigma_cutoff, fit_roi_sizes, min_fit_roi_sizes,\n",
    "                    return_amplitudes=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    filter_sigma_small = (sigma_z_small, sigma_xy_small, sigma_xy_small)\n",
    "    filter_sigma_large = (sigma_z_large, sigma_xy_large, sigma_xy_large)\n",
    "\n",
    "    kernel_small = localize.get_filter_kernel(filter_sigma_small, pixel_sizes, sigma_cutoff=sigma_cutoff)\n",
    "    kernel_large = localize.get_filter_kernel(filter_sigma_large, pixel_sizes, sigma_cutoff=sigma_cutoff)\n",
    "\n",
    "    img_high_pass = localize.filter_convolve(img, kernel_small, use_gpu=False)\n",
    "    img_low_pass = localize.filter_convolve(img, kernel_large, use_gpu=False)\n",
    "    img_filtered = img_high_pass - img_low_pass\n",
    "    # apply threshold found with Napari\n",
    "    img_filtered[img_filtered < dog_thresh] = 0\n",
    "\n",
    "    footprint = localize.get_max_filter_footprint(min_separations=min_separations, drs=pixel_sizes)\n",
    "    # array of size nz, ny, nx of True\n",
    "\n",
    "    centers_guess_inds, amps = localize.find_peak_candidates(img_filtered, footprint, threshold=dog_thresh)\n",
    "\n",
    "    # we don't return roi_sizes because we would have to manage it in\n",
    "    # the detect_spots_tile function, whereas another method could not output it\n",
    "    roi_coords = get_roi_coordinates(\n",
    "        centers = centers_guess_inds, \n",
    "        sizes = fit_roi_sizes, \n",
    "        max_coords_val = np.array(img.shape) - 1, \n",
    "        min_sizes = min_fit_roi_sizes,\n",
    "    )\n",
    "\n",
    "    if return_amplitudes:\n",
    "        return roi_coords, amps\n",
    "    else:\n",
    "        return roi_coords\n",
    "    \n",
    "\n",
    "def estimate_center_gauss(img, roi_coords, amps, sigma_xy, sigma_z):\n",
    "    \n",
    "    roi_sizes = roi_coords[:, 1, :] - roi_coords[:, 0, :]\n",
    "    centers_guess = (roi_sizes / 2)\n",
    "    \n",
    "    # Gaussian fit to find center of each spot\n",
    "    # amplitudes = []\n",
    "    centers = []\n",
    "    # sigmas = []\n",
    "    # chi_squareds = []\n",
    "    # all_res = []\n",
    "    for i in range(len(roi_coords)):\n",
    "        # extract ROI\n",
    "        roi = extract_ROI(img, roi_coords[i])\n",
    "        # fit gaussian in ROI\n",
    "        init_params = np.array([\n",
    "            amps[i], \n",
    "            centers_guess[i, 2],\n",
    "            centers_guess[i, 1],\n",
    "            centers_guess[i, 0],\n",
    "            sigma_xy, \n",
    "            sigma_z, \n",
    "            roi.min(),\n",
    "        ])\n",
    "        fit_results = localize.fit_gauss_roi(\n",
    "            roi, \n",
    "            (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "            init_params,\n",
    "            fixed_params=np.full_like(init_params, False),\n",
    "        )\n",
    "        amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = fit_results['fit_params']\n",
    "        # amplitudes.append(amplitude)\n",
    "        centers.append([center_z, center_y, center_x])\n",
    "        # sigmas.append([sigma_xy, sigma_z])\n",
    "        # chi_squareds.append(fit_results['chi_squared'])\n",
    "        # all_res.append(fit_results['fit_params'])\n",
    "    # add origin coordinates of each ROI\n",
    "    centers = np.array(centers) + roi_coords[:, 0, :]\n",
    "    \n",
    "    return centers\n",
    "\n",
    "\n",
    "def shift_coordinates(spots_coords, tile_coords, format='pair'):\n",
    "    \n",
    "    if format == 'pair':\n",
    "        spots_coords = spots_coords + tile_coords[:, 0, :]\n",
    "    elif format == 'single':\n",
    "        spots_coords = spots_coords + tile_coords\n",
    "    return spots_coords\n",
    "    \n",
    "\n",
    "def detect_spots_tile(tile, tile_coords=None, \n",
    "                      roi_method=detect_blob_dog, roi_kwargs=None,\n",
    "                      center_method=estimate_center_gauss, center_kwargs=None,\n",
    "                      filter_method=None, filter_kwargs=None):\n",
    "    \"\"\"\n",
    "    Find spots in a region of interest.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tile : numpy.ndarray\n",
    "        A ND image where we want to find spots.\n",
    "    tile_coords : Union[Tuple, List, np.ndarray]\n",
    "        The coordinates of the 'lowest' corner of the tile in the\n",
    "        bigger image it is extracted from.\n",
    "    roi_method : fct\n",
    "        Method used to define ROI around detect potential spots.\n",
    "    roi_kwargs : dict\n",
    "        Optional arguments for the blob detection method.\n",
    "    center_method : fct\n",
    "        Method used to decipher more precisely spots coordinates\n",
    "    center_kwargs : dict\n",
    "        Optional arguments for the center method.\n",
    "    filter_method : str\n",
    "        Method used to discard wrong spots.\n",
    "    filter_kwargs : str\n",
    "        Optional arguments for the filter method.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    spots_coords : numpy.ndarray\n",
    "        The coordinates in the bigger image reference system of all spots.\n",
    "    \"\"\"\n",
    "    \n",
    "    if roi_method is not None:\n",
    "        rois_coords = roi_method(tile, roi_kwargs)\n",
    "        spots_coords = center_method(tile, rois_coords, **center_kwargs)\n",
    "    else:\n",
    "        # case where no pre-detection of ROIs is needed\n",
    "        spots_coords = center_method(tile, **center_kwargs)\n",
    "        \n",
    "    if tile_coords is not None:\n",
    "        spots_coords = shift_coordinates(spots_coords, tile_coords)\n",
    "    \n",
    "    if filter_method is not None:\n",
    "        spots_coords = filter_method(spots_coords, **filter_kwargs)\n",
    "    \n",
    "    return spots_coords\n",
    "\n",
    "def merge_spots_coords(all_coords):\n",
    "    \"\"\"\n",
    "    Merge a list of spots coordinates into a single array.\n",
    "    Useful to aggregate data analyses distributed on several places.\n",
    "    \"\"\"\n",
    "    return np.vstack(all_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of spots in pixels\n",
    "sx = sy = 5\n",
    "sz = 20\n",
    "# FWHM = 2.355 x sigma\n",
    "sigma_xy = sx / 2.355\n",
    "sigma_z = sz / 2.355\n",
    "# to reproduce LoG with Dog we need sigma_big = 1.6 * sigma_small\n",
    "sigma_xy_small = sigma_xy / 1.6**(1/2)\n",
    "sigma_xy_large = sigma_xy * 1.6**(1/2)\n",
    "sigma_z_small = sigma_z / 1.6**(1/2)\n",
    "sigma_z_large = sigma_z * 1.6**(1/2)\n",
    "\n",
    "fit_roi_sizes = (1.5 * np.array([sz, sy, sx])).astype(int)\n",
    "\n",
    "tile = img\n",
    "tile_coords = None\n",
    "roi_method = detect_blob_dog\n",
    "roi_kwargs = {\n",
    "    'sigma_xy_small': sigma_xy / 1.6**(1/2),\n",
    "    'sigma_xy_large': sigma_xy * 1.6**(1/2),\n",
    "    'sigma_z_small': sigma_z / 1.6**(1/2),\n",
    "    'sigma_z_large': sigma_z * 1.6**(1/2),\n",
    "    'dog_thresh': 4,\n",
    "    'min_separations': (10, 3, 3), \n",
    "    'pixel_sizes': (1, 1, 1),\n",
    "    'sigma_cutoff': 2, \n",
    "    'fit_roi_sizes': fit_roi_sizes, \n",
    "    'min_fit_roi_sizes': fit_roi_sizes,\n",
    "    'return_amplitudes': True,\n",
    "}\n",
    "center_method = estimate_center_gauss\n",
    "center_kwargs = {\n",
    "    'sigma_xy': sigma_xy, \n",
    "    'sigma_z': sigma_z,\n",
    "}\n",
    "filter_method = None\n",
    "filter_kwargs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965dfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_coords, amps = roi_method(tile, **roi_kwargs)\n",
    "print(rois_coords)\n",
    "print(rois_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73db45",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "spots_coords = center_method(tile, rois_coords, amps, **center_kwargs)\n",
    "print(spots_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc49fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(spots_coords, name='fitted centers', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186c98f",
   "metadata": {},
   "source": [
    "#### with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47de3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_coords = delayed(roi_method)(tile, **roi_kwargs)\n",
    "spots_coords = delayed(estimate_center_gauss)(tile, rois_coords, **center_kwargs)\n",
    "print(spots_coords)\n",
    "print(spots_coords.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7951446",
   "metadata": {},
   "source": [
    "#### On multiple tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = 512\n",
    "start_y = 1000\n",
    "start_z = 128\n",
    "size_xy = 128 * 2\n",
    "size_z  = 128 * 2\n",
    "img = im[start_z:(start_z+size_z), start_y:(start_y+size_xy), start_x:(start_x+size_xy)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_shape = np.array([128, 128, 128]) + fit_roi_sizes\n",
    "overlap = fit_roi_sizes - 1\n",
    "\n",
    "tiler = Tiler(\n",
    "    data_shape=img.shape,\n",
    "    tile_shape=tile_shape,\n",
    "    overlap=overlap,\n",
    "    channel_dimension=None,\n",
    "    mode='irregular',\n",
    ")\n",
    "for tile_id, tile in tiler.iterate(img):\n",
    "    coords = tiler.get_tile_bbox(tile_id=tile_id)\n",
    "    print(coords)\n",
    "    print(tile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_spots_coords = []\n",
    "for tile_id, tile in tiler.iterate(img):\n",
    "    print(tile_id)\n",
    "    # origin coordinates of the tile\n",
    "    tile_coords_ori = tiler.get_tile_bbox(tile_id=tile_id)[0]\n",
    "    # get spots ROIs coordinates in the tile\n",
    "    rois_coords, amps = roi_method(tile, **roi_kwargs)\n",
    "    # fit tile's spots with gaussian\n",
    "    spots_coords = center_method(tile, rois_coords, amps, **center_kwargs)\n",
    "    # add origin coordinates to tile's spots' coordinates\n",
    "    spots_coords = spots_coords + tile_coords_ori\n",
    "    # save in global list of coordinates\n",
    "    tiled_spots_coords.append(spots_coords)\n",
    "\n",
    "tiled_spots_coords =  np.vstack(tiled_spots_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b492287",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Compare with the monolithic detection"
   },
   "outputs": [],
   "source": [
    "\n",
    "# get spots ROIs coordinates in the tile\n",
    "rois_coords, amps = roi_method(img, **roi_kwargs)\n",
    "# fit tile's spots with gaussian\n",
    "whole_spots_coords = center_method(img, rois_coords, amps, **center_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e04d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(img, name='img')\n",
    "# viewer.add_points(whole_spots_coords, name='whole_spots_coords', blending='additive', size=3, face_color='g')\n",
    "# viewer.add_points(tiled_spots_coords, name='tiled_spots_coords', blending='additive', size=3, face_color='r')\n",
    "\n",
    "# There are 3 more points in  the tilted version, apparently near the overlapping regions. Maybe the DoG is too sensitive to\n",
    "# end of tiles. The points can be easily filtered out as they are clearly not on a real spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d36b26",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Use Dask"
   },
   "outputs": [],
   "source": [
    "def get_tile_coords_ori(tiler, tile_id):\n",
    "    return tiler.get_tile_bbox(tile_id=tile_id)[0]\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccb79a",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Use Dask"
   },
   "outputs": [],
   "source": [
    "nb_cores = os.cpu_count()\n",
    "client = Client(n_workers=nb_cores)\n",
    "# cluster = LocalCluster(n_workers=4, threads_per_worker=2)\n",
    "# client = Client(cluster, asynchronous=True)\n",
    "\n",
    "tiled_spots_coords = []\n",
    "for tile_id, tile in tiler.iterate(img):\n",
    "    print(tile_id)\n",
    "    # origin coordinates of the tile\n",
    "    tile_coords_ori = delayed(get_tile_coords_ori)(tiler, tile_id)\n",
    "    # get spots ROIs coordinates in the tile\n",
    "    rois_coords, amps = delayed(roi_method, nout=2)(tile, **roi_kwargs)\n",
    "    # fit tile's spots with gaussian\n",
    "    spots_coords = delayed(center_method)(tile, rois_coords, amps, **center_kwargs)\n",
    "    # add origin coordinates to tile's spots' coordinates\n",
    "    spots_coords = delayed(shift_coordinates)(spots_coords, tile_coords_ori, 'single')\n",
    "    # save in global list of coordinates\n",
    "    tiled_spots_coords.append(spots_coords)\n",
    "\n",
    "aggregated_spots_coords =  delayed(merge_spots_coords)(tiled_spots_coords)\n",
    "aggregated_spots_coords.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650cfd7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "coords = aggregated_spots_coords.compute()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af801f48",
   "metadata": {},
   "source": [
    "## Include filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = {\n",
    "    'filter_amplitude_min': 20,\n",
    "    'filter_amplitude_max': False,\n",
    "    'filter_sigma_xy_min': 0.5,\n",
    "    'filter_sigma_xy_max': 5,\n",
    "    'filter_sigma_z_min': 2,\n",
    "    'filter_sigma_z_max': 20,\n",
    "    'filter_sigma_ratio_min': 1,\n",
    "    'filter_sigma_ratio_max': 5,\n",
    "    'filter_chi_squared': 200,\n",
    "    'filter_dist_center': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter_spots(filter_vars, filter_params):\n",
    "    \"\"\"\n",
    "    Filter out spots based on gaussian fit results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_vars : dict\n",
    "        Variables used to compute boolean filters.\n",
    "    filter_params : dict\n",
    "        Parameters (thresholds) applied to their corresponding variables.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    spot_select : array\n",
    "        Bolean vector of spots to keep.\n",
    "    \"\"\"\n",
    "\n",
    "    # list of boolean filters for all spots thresholds\n",
    "    selectors = []\n",
    "\n",
    "    if filter_params['filter_amplitude_min']:\n",
    "        selectors.append(filter_vars['amplitudes'] >= filter_params['filter_amplitude_min'])\n",
    "    if filter_params['filter_amplitude_max']:\n",
    "        selectors.append(filter_vars['amplitudes'] <= filter_params['filter_amplitude_max'])\n",
    "    if filter_params['filter_sigma_xy_min']:\n",
    "        selectors.append(filter_vars['sigmas_xy'] >= filter_params['filter_sigma_xy_min'])\n",
    "    if filter_params['filter_sigma_xy_max']:\n",
    "        selectors.append(filter_vars['sigmas_xy'] <= filter_params['filter_sigma_xy_max'])\n",
    "    if filter_params['filter_sigma_z_min']:\n",
    "        selectors.append(filter_vars['sigmas_z'] >= filter_params['filter_sigma_z_min'])\n",
    "    if filter_params['filter_sigma_z_max']:\n",
    "        selectors.append(filter_vars['sigmas_z'] <= filter_params['filter_sigma_z_max'])\n",
    "    if filter_params['filter_sigma_ratio_min']:\n",
    "        selectors.append(filter_vars['sigma_ratios'] >= filter_params['filter_sigma_ratio_min'])\n",
    "    if filter_params['filter_sigma_ratio_max']:\n",
    "        selectors.append(filter_vars['sigma_ratios'] <= filter_params['filter_sigma_ratio_max'])\n",
    "    if filter_params['filter_chi_squared']:\n",
    "        selectors.append(filter_vars['chi_squared'] >= filter_params['filter_chi_squared'])\n",
    "    if filter_params['filter_dist_center']:\n",
    "        selectors.append(filter_vars['dist_center'] <= filter_params['filter_dist_center'])\n",
    "\n",
    "    if len(selectors) == 0:\n",
    "        print(\"No filter is active\")\n",
    "    else:\n",
    "        spot_select = np.logical_and.reduce(selectors)\n",
    "    \n",
    "    return spot_select\n",
    "\n",
    "def apply_filter_spots(spots_coords, spot_select):\n",
    "    return spots_coords[spot_select, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a46115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_center_gauss(img, roi_coords, amps, sigma_xy, sigma_z, return_fit_vars=True):\n",
    "    \n",
    "    roi_sizes = roi_coords[:, 1, :] - roi_coords[:, 0, :]\n",
    "    centers_guess = (roi_sizes / 2)\n",
    "    \n",
    "    # Gaussian fit to find center of each spot\n",
    "    all_res = []\n",
    "    chi_squared = []\n",
    "    for i in range(len(roi_coords)):\n",
    "        # extract ROI\n",
    "        roi = extract_ROI(img, roi_coords[i])\n",
    "        # fit gaussian in ROI\n",
    "        init_params = np.array([\n",
    "            amps[i], \n",
    "            centers_guess[i, 2],\n",
    "            centers_guess[i, 1],\n",
    "            centers_guess[i, 0],\n",
    "            sigma_xy, \n",
    "            sigma_z, \n",
    "            roi.min(),\n",
    "        ])\n",
    "        fit_results = localize.fit_gauss_roi(\n",
    "            roi, \n",
    "            (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "            init_params,\n",
    "            fixed_params=np.full_like(init_params, False),\n",
    "        )\n",
    "        chi_squared.append(fit_results['chi_squared'])\n",
    "        all_res.append(fit_results['fit_params'])\n",
    "        \n",
    "    # process all the results\n",
    "    all_res = np.array(all_res)\n",
    "    amplitudes = all_res[:, 0]\n",
    "    centers = all_res[:, 3:0:-1]\n",
    "    sigmas_xy = all_res[:, 4]\n",
    "    sigmas_z = all_res[:, 5]\n",
    "    # offsets = all_res[:, 6]\n",
    "    chi_squared = np.array(chi_squared)\n",
    "    # distances from initial guess\n",
    "    dist_center = np.sqrt(np.sum((centers - centers_guess)**2, axis=1))\n",
    "    # add origin coordinates of each ROI\n",
    "    centers = centers + roi_coords[:, 0, :]\n",
    "    # composed variables for filtering\n",
    "    sigma_ratios = sigmas_z / sigmas_xy\n",
    "    \n",
    "    fit_vars = {\n",
    "    'amplitudes': amplitudes,\n",
    "    'sigmas_xy': sigmas_xy,\n",
    "    'sigmas_z': sigmas_z,\n",
    "    # 'offsets': offsets,\n",
    "    'chi_squared': chi_squared,\n",
    "    'dist_center': dist_center,\n",
    "    'sigma_ratios': sigma_ratios,\n",
    "    }        \n",
    "    \n",
    "    if return_fit_vars:\n",
    "        return centers, fit_vars\n",
    "    else:\n",
    "        return centers\n",
    "\n",
    "center_method = estimate_center_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de29db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=nb_cores)\n",
    "\n",
    "tiled_spots_coords = []\n",
    "for tile_id, tile in tiler.iterate(img):\n",
    "    print(tile_id)\n",
    "    # origin coordinates of the tile\n",
    "    tile_coords_ori = delayed(get_tile_coords_ori)(tiler, tile_id)\n",
    "    # get spots ROIs coordinates in the tile\n",
    "    rois_coords, amps = delayed(roi_method, nout=2)(tile, **roi_kwargs)\n",
    "    # fit tile's spots with gaussian\n",
    "    spots_coords, fit_vars = delayed(center_method, nout=2)(tile, rois_coords, amps, **center_kwargs)\n",
    "    # make spots boolean selector\n",
    "    spot_select = delayed(make_filter_spots)(fit_vars, filter_params)\n",
    "    # apply filter on spots\n",
    "    spots_coords = delayed(apply_filter_spots)(spots_coords, spot_select)\n",
    "    # add origin coordinates to tile's spots' coordinates\n",
    "    spots_coords = delayed(shift_coordinates)(spots_coords, tile_coords_ori, 'single')\n",
    "    # save in global list of coordinates\n",
    "    tiled_spots_coords.append(spots_coords)\n",
    "\n",
    "aggregated_spots_coords = delayed(merge_spots_coords)(tiled_spots_coords)\n",
    "aggregated_spots_coords.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = aggregated_spots_coords.compute()\n",
    "print(f'Found {coords.shape[0]} spots')\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4978eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's working! I just need to select appropriate filter thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad0ffb",
   "metadata": {},
   "source": [
    "## Automated spot filtering parameters selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550182b",
   "metadata": {},
   "source": [
    "We need a method to autoatically select the best parameters combination to filter spots.  \n",
    "That requires a performance metrics.  \n",
    "We can first match spots that are within a given distance (related to PSF), we can use one distance for the xy plane, and another one for the z axis. We will need to adapt that for tilted configuration. Points can be only matched to a single other point, select the closest one.\n",
    "Then can compute true and false positives and negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ae638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_closest_points(ref, target, k=1):\n",
    "    \"\"\"\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> ref = np.array([[0, 0, 0], [10, 0, 0], [0, 10, 0]])\n",
    "    >>> target = np.array([[1, 1, 1], [7, 0, 0], [0, 0, 10], [5, 0, 0], [0, 11, 0]])\n",
    "    >>> match_closest_points(source, target)\n",
    "        array([0, 1, 0, 0, 2])\n",
    "    \"\"\"\n",
    "    from scipy.spatial import cKDTree\n",
    "    kdt_ref = KDTree(ref)\n",
    "\n",
    "    # closest node id and discard computed distances ('_,')\n",
    "    _, matched_ids = kdt_ref.query(x=target, k=k)\n",
    "    return matched_ids\n",
    "\n",
    "def compute_distances(source, target, method='xy_z_orthog', dist_fct='euclidian', tilt_vector=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : ndarray\n",
    "        Coordinates of the first set of points.\n",
    "    target : ndarray\n",
    "        Coordinates of the second set of points.\n",
    "    method : str\n",
    "        Method used to compute distances. If 'xyz', standard distances are computed considering all axes\n",
    "        simultaneously. If 'xy_z_orthog' 2 distances are computed, for the xy pkane and along the z axis \n",
    "        respectively. If 'xy_z_tilted' 2 distances are computed for the tilted plane and  its normal axis.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
    "    >>> target = np.array([[0, 0, 0], [-3, 0, 2], [0, 0, 10]])\n",
    "    >>> distance(source, target)\n",
    "        (array([0, 4, 0]), array([0., 2., 5.]))\n",
    "    >>> distance(source, target, dist_fct='L1')\n",
    "        (array([0, 4, 0]), array([0, 2, 7]))\n",
    "    \n",
    "    \"\"\"\n",
    "    if method == 'xyz':\n",
    "        if dist_fct == 'euclidian':\n",
    "            dist = np.sqrt(np.sum((source - target)**2, axis=1))\n",
    "        elif dist_fct == 'L1':\n",
    "            dist = np.sum((source - target), axis=1)\n",
    "        else:\n",
    "            dist = dist_fct(source, target, axis=1)\n",
    "        return dist\n",
    "    elif method == 'xy_z_orthog':\n",
    "        if dist_fct == 'euclidian':\n",
    "            dist_xy = np.sqrt(np.sum((source[:, 1:] - target[:, 1:])**2, axis=1))\n",
    "            dist_z = np.abs(source[:, 0] - target[:, 0])\n",
    "        elif dist_fct == 'L1':\n",
    "            dist_xy = np.sum(np.abs((source[:, 1:]  - target[:, 1:])), axis=1)\n",
    "            dist_z = np.abs(source[:, 0] - target[:, 0])\n",
    "        else:\n",
    "            dist_xy = dist_fct(source[:, 1:], target[:, 1:], axis=1)\n",
    "            dist_z = dist_fct(source[:, 0], target[:, 0])\n",
    "        return dist_z, dist_xy\n",
    "    elif method == 'xy_z_tilted':\n",
    "        raise NotImplementedError(\"Method 'xy_z_tilted' will be implemented soon\")\n",
    "\n",
    "\n",
    "def make_counts_array(data, return_all=True):\n",
    "    \"\"\"\n",
    "    Return a vector of counts of same size as data.\n",
    "    \"\"\"\n",
    "    uniq, counts = np.unique(data, return_counts=True)\n",
    "    if return_all:\n",
    "        return uniq, counts, counts[data]\n",
    "    else:\n",
    "        return counts[data]\n",
    "\n",
    "\n",
    "def remove_multiple_links(matched_ids, coords, dist_z, dist_xy):\n",
    "    \"\"\"\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> matched_ids = np.array([2, 0, 1, 0, 1, 0])\n",
    "    >>> coords = np.array([[2, 2, 2], [0, 0, 0], [1, 1, 1], [0, 10, 0], [1, 1, 10], [0, 0, 10]])\n",
    "    >>> dist_z = np.array([0, 0, 0, 10, 10, 10])\n",
    "    >>> dist_xy = np.array([0, 0, 0, 10, 10, 10])\n",
    "    >>> remove_multiple_links(matched_ids, coords, dist_z, dist_xy)\n",
    "        (array([2, 0, 1]),\n",
    "         array([[2, 2, 2],\n",
    "                [0, 0, 0],\n",
    "                [1, 1, 1]]))\n",
    "    \"\"\"\n",
    "    matched_uniq, matched_counts, counts_array = make_counts_array(matched_ids)\n",
    "    select_duplicated_array = counts_array != 1\n",
    "    if select_duplicated_array.sum() == 0:\n",
    "        return matched_uniq, coords\n",
    "    else:\n",
    "        # start with a copy of unique matches and coordinates\n",
    "        matched_ids_single = matched_ids[~select_duplicated_array]\n",
    "        coords_single = coords[~select_duplicated_array]\n",
    "        # then add a single match and set of coordinates per duplicated match\n",
    "        select_duplicated_uniq = matched_counts != 1\n",
    "        for i in matched_uniq[select_duplicated_uniq]:\n",
    "            select = matched_ids == i\n",
    "            coords_duplicated = coords[select]\n",
    "            dist_tot = dist_z[select] + dist_xy[select]\n",
    "            min_id = np.argmin(dist_tot)\n",
    "            matched_ids_single = np.hstack((matched_ids_single, i))\n",
    "            coords_single = np.vstack((coords_single, coords_duplicated[min_id]))\n",
    "        return matched_ids_single, coords_single\n",
    "    \n",
    "    \n",
    "def match_spots(ref, target, thresh_z=15, thresh_xy=5):\n",
    "    \"\"\"\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> ref = np.array([[0, 0, 0], [10, 0, 0], [0, 10, 0]])\n",
    "    >>> target = np.array([[11, 0, 0], [1, 0, 0], [12, 0, 0], [100, 0, 0], [1, 1, 1], [0, 12, 0]])\n",
    "    >>> match_spots(ref, target, thresh_z=15, thresh_xy=5)\n",
    "    (array([2, 0, 1]),\n",
    "     array([[ 0, 12,  0],\n",
    "            [ 1,  0,  0],\n",
    "            [11,  0,  0]]))\n",
    "    \"\"\"\n",
    "    # match all target points to reference points\n",
    "    matched_ids = match_closest_points(ref, target)\n",
    "    # compute separately distances in plane and along z axis\n",
    "    dist_z, dist_xy = compute_distances(ref[matched_ids], target, method='xy_z_orthog', dist_fct='euclidian')\n",
    "    # threshold on both distances\n",
    "    select = np.logical_and(dist_z < thresh_z, dist_xy < thresh_xy)\n",
    "    matched_ids = matched_ids[select]\n",
    "    target = target[select]\n",
    "    dist_z = dist_z[select]\n",
    "    dist_xy = dist_xy[select]\n",
    "    # remove multiple links from single spots\n",
    "    matched_ids_single, target_single = remove_multiple_links(matched_ids, target, dist_z, dist_xy)\n",
    "    return matched_ids_single, target_single\n",
    "\n",
    "def evaluate_spot_detection_performance(nb_ref, nb_pred, matched_ids):\n",
    "\n",
    "    # matched_ids is contained in the sets of ref spots and pred spots.\n",
    "    TP = len(matched_ids)\n",
    "    FP = nb_pred - len(matched_ids)\n",
    "    FN = nb_ref - len(matched_ids)\n",
    "    \n",
    "    F1 = TP / (TP + 0.5 * (FP + FN))\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c14aa",
   "metadata": {},
   "source": [
    "We will implement the automated parameters selection in the future, the priority is detecting spots in the native tilted plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53041eac",
   "metadata": {},
   "source": [
    "## Spot detection in tilted plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f9734",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_NDTiff(path_dataset, channels=None, z_levels=None, squeeze=True):\n",
    "    \"\"\"\n",
    "    Open an NDTiff image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_dataset : str\n",
    "        Path of the image.\n",
    "    channels : None or list(int)\n",
    "        If None, load all channels, else load a list of channels.\n",
    "    z_levels : None or array\n",
    "        If None, load all z slices, else load a list of slices.\n",
    "    \n",
    "    Returns:\n",
    "    img : ndarray\n",
    "        A numpy ndimage.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = Dataset(path_dataset)\n",
    "    # use metadata to guess how to load the image\n",
    "    meta = dataset.axes\n",
    "    c = np.array([x for x in meta['c']])  # array([1, 2, 3])\n",
    "    chan = np.array([x for x in meta['channel']])\n",
    "    if chan.size == 1:\n",
    "        chan_dict = {x: chan[0] for x in c}\n",
    "    elif chan.size == c.size:\n",
    "        shift = int(np.unique(c.min() - chan))\n",
    "        chan_dict = {c[i]: chan[i] for i in range(len(c))}\n",
    "    else:\n",
    "        raise(\"`c` and `channel` don't match.\")\n",
    "    \n",
    "    if z_levels is None:\n",
    "        z_levels = np.array([x for x in meta['z']])\n",
    "\n",
    "    # load one image to get more info\n",
    "    sample = dataset.read_image(z=int(np.median(z_levels)), c=c[0], channel=chan_dict[c[0]])\n",
    "    nb_z = z_levels.size\n",
    "    nb_y, nb_x = sample.shape\n",
    "\n",
    "    # iterativelly load all z planes of all channels\n",
    "    if channels is None:\n",
    "        channels = list(c) # convert to list for downstream compatibility\n",
    "    else:\n",
    "        # detect what could go wrong\n",
    "        if isinstance(channels, int):\n",
    "            channels = [channels]\n",
    "        warn_channels = [x for x in channels if x not in c]\n",
    "        if len(warn_channels) > 0:\n",
    "            print(\"WARNING these channels are not in the dataset:\")\n",
    "            print(warn_channels)\n",
    "        channels = [x for x in channels if x in c]\n",
    "        if len(channels) == 0:\n",
    "            print(\"WARNING there is no requested channel in the dataset, returning\")\n",
    "            return\n",
    "    nb_ch = len(channels)\n",
    "    img = np.zeros((nb_ch, nb_z, nb_y, nb_x), dtype=sample.dtype)\n",
    "    for i, channel_id in enumerate(channels):\n",
    "        print(\"    channel id: {}\".format(channel_id))\n",
    "        for z_id, z in enumerate(z_levels):\n",
    "            img[i, z_id, :, :] = dataset.read_image(z=z, c=channel_id, channel=chan_dict[channel_id])\n",
    "    \n",
    "    if squeeze:\n",
    "        img = np.squeeze(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opened                 \n",
      "    channel id: 2\n",
      "(2620, 512, 1856)\n"
     ]
    }
   ],
   "source": [
    "dir_load = Path('../../../from_server/example_image_tilted_z0')\n",
    "path_im = dir_load / '16plex_lung_r0000_y0000_z0000_1'\n",
    "\n",
    "channel = [2]\n",
    "\n",
    "im = open_NDTiff(\n",
    "    path_im.as_posix(),\n",
    "    channels=channel,\n",
    "    squeeze=True)\n",
    "print(im.shape)\n",
    "# np.squeeze in open_NDTiff exchanged z and y axes\n",
    "# im = np.swapaxes(im, -3, -2)\n",
    "# print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4374965",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = 800\n",
    "start_y = 1500\n",
    "start_z = 0\n",
    "size_x = 512\n",
    "size_y = 800\n",
    "size_z = 256\n",
    "\n",
    "# There is a difference of definition between z and y for the microscope and for python:\n",
    "# tilted xy images are aquired while the stage is moving\n",
    "# successive images are stacked in a third \"z\" dimension\n",
    "# but in the physical space this is the y direction, the physical z is the y axis of the image\n",
    "\n",
    "# img = im[start_z:start_z+size_z, start_y:start_y+size_y, start_x:start_x+size_x]\n",
    "img = im[start_y:start_y+size_y, start_z:start_z+size_z, start_x:start_x+size_x]\n",
    "mini = img.min()\n",
    "maxi = img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6961a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x7fd2f7556f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "# viewer.add_image(img_high_pass, name='img_high_pass')\n",
    "# viewer.add_image(img_low_pass, name='img_low_pass')\n",
    "viewer.add_image(img, name='img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from localize_psf import data_io\n",
    "\n",
    "scan_data_path = dir_load / \"scan_metadata.csv\"\n",
    "scan_data = data_io.read_metadata(scan_data_path)\n",
    "\n",
    "nt = scan_data[\"num_t\"]\n",
    "nyp = scan_data[\"y_pixels\"]\n",
    "nxp = scan_data[\"x_pixels\"]\n",
    "dc = scan_data[\"pixel_size\"] / 1000\n",
    "dstage = scan_data[\"scan_step\"] / 1000\n",
    "theta = scan_data[\"theta\"] * np.pi / 180\n",
    "normal = np.array([0, -np.sin(theta), np.cos(theta)])  # normal of camera pixel\n",
    "\n",
    "num_r = scan_data['num_r']\n",
    "num_y = scan_data['num_y']\n",
    "num_z = scan_data['num_z']\n",
    "num_ch = scan_data['num_ch']\n",
    "num_images = scan_data['scan_axis_positions']\n",
    "excess_images = scan_data['excess_scan_positions']\n",
    "nimgs_per_vol = num_images + excess_images\n",
    "\n",
    "# trapezoid volume\n",
    "volume_um3 = (dstage * nimgs_per_vol) * (dc * np.sin(theta) * nyp) * (dc * nxp)\n",
    "\n",
    "# ###############################\n",
    "# load/set parameters for all datasets\n",
    "# ###############################\n",
    "chunk_size_planes = 1000\n",
    "chunk_size_x = 300\n",
    "# chunk_size_planes = 300\n",
    "# chunk_size_x = 150\n",
    "chunk_overlap = 10\n",
    "channel_to_use = [False, True, True]\n",
    "excitation_wavelengths = np.array([0.488, 0.561, 0.635])\n",
    "emission_wavelengths = np.array([0.515, 0.600, 0.680])\n",
    "thresholds = np.array([np.nan, 100, 25])\n",
    "fit_thresholds = np.array([np.nan, 100, 25])\n",
    "na = 1.\n",
    "ni = 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296ae97",
   "metadata": {},
   "source": [
    "### DoG filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b56335",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 2\n",
    "# Peter's code\n",
    "\n",
    "# sigma_xy = 0.22 * emission_wavelengths[ch] / na\n",
    "# sigma_z = np.sqrt(6) / np.pi * ni * emission_wavelengths[ch] / na ** 2\n",
    "sigma_xy = psf.na2sxy(na, emission_wavelengths[ch])\n",
    "sigma_z = psf.na2sz(na, emission_wavelengths[ch], ni)\n",
    "\n",
    "# difference of gaussian filer\n",
    "filter_sigma_small = (0.5 * sigma_z, 0.25 * sigma_xy, 0.25 * sigma_xy)\n",
    "filter_sigma_large = (3 * sigma_z, 3 * sigma_xy, 3 * sigma_xy)\n",
    "# fit roi size\n",
    "roi_size = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "# assume points closer together than this come from a single bead\n",
    "min_spot_sep = (3 * sigma_z, 3 * sigma_xy)\n",
    "# exclude points with sigmas outside these ranges\n",
    "sigmas_min = (0.25 * sigma_z, 0.25 * sigma_xy)\n",
    "sigmas_max = (3 * sigma_z, 4 * sigma_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - dc: 0.115  \n",
      "  - theta: 0.524  \n",
      "  - dstage: 0.4  \n",
      "  - sigma_xy: 0.162  \n",
      "  - sigma_z: 0.742  \n",
      "  - sigma_xy_small: 0.04  \n",
      "  - sigma_xy_large: 0.648  \n",
      "  - sigma_z_small: 0.186  \n",
      "  - sigma_z_large: 2.227  \n"
     ]
    }
   ],
   "source": [
    "print(f\"  - dc: {np.round(dc, 3)}  \")\n",
    "print(f\"  - theta: {np.round(theta, 3)}  \")\n",
    "print(f\"  - dstage: {np.round(dstage, 3)}  \")\n",
    "print(f\"  - sigma_xy: {np.round(sigma_xy, 3)}  \")\n",
    "print(f\"  - sigma_z: {np.round(sigma_z, 3)}  \")\n",
    "print(f\"  - sigma_xy_small: {np.round(sigmas_min[1], 3)}  \")\n",
    "print(f\"  - sigma_xy_large: {np.round(sigmas_max[1], 3)}  \")\n",
    "print(f\"  - sigma_z_small: {np.round(sigmas_min[0], 3)}  \")\n",
    "print(f\"  - sigma_z_large: {np.round(sigmas_max[0], 3)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = localize_skewed.get_filter_kernel_skewed(filter_sigma_small, dc, theta, dstage, sigma_cutoff=2)\n",
    "kl = localize_skewed.get_filter_kernel_skewed(filter_sigma_large, dc, theta, dstage, sigma_cutoff=2)\n",
    "# imgs_hp = localize.filter_convolve(img, ks, use_gpu=True)\n",
    "# imgs_lp = localize.filter_convolve(img, kl, use_gpu=True)\n",
    "imgs_hp = localize.filter_convolve(img, np.flip(np.swapaxes(ks, 0, 1), axis=0), use_gpu=True)\n",
    "imgs_lp = localize.filter_convolve(img, np.flip(np.swapaxes(kl, 0, 1), axis=0), use_gpu=True)\n",
    "imgs_filtered = imgs_hp - imgs_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b378e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "# viewer.add_image(ks, name='kernel small', colormap='green', blending='additive')\n",
    "# viewer.add_image(kl, name='kernel large', colormap='red', blending='additive')\n",
    "# viewer.add_image(np.flip(kl, axis=1), name='kernel large flipped', colormap='blue', blending='additive')\n",
    "# viewer.add_image(np.swapaxes(kl, 0, 1), name='kernel large swap 0-1', blending='additive')\n",
    "viewer.add_image(np.flip(np.swapaxes(ks, 0, 1), axis=0), name='kernel small swap 0-1 flip 0', blending='additive')  # that's the good one!\n",
    "viewer.add_image(np.flip(np.swapaxes(kl, 0, 1), axis=0), name='kernel large swap 0-1 flip 0', blending='additive')  # that's the good one!\n",
    "# but the big kernel looks really big compared to tilted spots\n",
    "viewer.add_image(img, name='img', blending='additive')\n",
    "viewer.add_image(imgs_filtered, name='imgs_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - sx: 0.7  \n",
      "  - sz: 2  \n",
      "  - sigma_xy: 0.297  \n",
      "  - sigma_z: 0.849  \n",
      "  - sigma_xy_small: 0.235  \n",
      "  - sigma_xy_large: 0.376  \n",
      "  - sigma_z_small: 0.671  \n",
      "  - sigma_z_large: 1.074  \n"
     ]
    }
   ],
   "source": [
    "# Choose by hand size of spots\n",
    "\n",
    "# size of spots in pixels\n",
    "sx = sy = 0.7\n",
    "sz = 2\n",
    "# FWHM = 2.355 x sigma\n",
    "sigma_xy = sx / 2.355\n",
    "sigma_z = sz / 2.355\n",
    "# to reproduce LoG with Dog we need sigma_big = 1.6 * sigma_small\n",
    "sigma_xy_small = sigma_xy / 1.6**(1/2)\n",
    "sigma_xy_large = sigma_xy * 1.6**(1/2)\n",
    "sigma_z_small = sigma_z / 1.6**(1/2)\n",
    "sigma_z_large = sigma_z * 1.6**(1/2)\n",
    "\n",
    "filter_sigma_small = (sigma_z_small, sigma_xy_small, sigma_xy_small)\n",
    "filter_sigma_large = (sigma_z_large, sigma_xy_large, sigma_xy_large)\n",
    "\n",
    "print(f\"  - sx: {np.round(sx, 3)}  \")\n",
    "print(f\"  - sz: {np.round(sz, 3)}  \")\n",
    "print(f\"  - sigma_xy: {np.round(sigma_xy, 3)}  \")\n",
    "print(f\"  - sigma_z: {np.round(sigma_z, 3)}  \")\n",
    "print(f\"  - sigma_xy_small: {np.round(sigma_xy_small, 3)}  \")\n",
    "print(f\"  - sigma_xy_large: {np.round(sigma_xy_large, 3)}  \")\n",
    "print(f\"  - sigma_z_small: {np.round(sigma_z_small, 3)}  \")\n",
    "print(f\"  - sigma_z_large: {np.round(sigma_z_large, 3)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - sigma_xy: 0.162  \n",
      "  - sigma_z: 0.742  \n",
      "  - sigma_xy_small: 0.128  \n",
      "  - sigma_xy_large: 0.205  \n",
      "  - sigma_z_small: 0.587  \n",
      "  - sigma_z_large: 0.939  \n"
     ]
    }
   ],
   "source": [
    "# Using Peter's functions for spot size, but with\n",
    "# standard DoG parameters\n",
    "\n",
    "# Peter's function\n",
    "sigma_xy = psf.na2sxy(na, emission_wavelengths[ch])\n",
    "sigma_z = psf.na2sz(na, emission_wavelengths[ch], ni)\n",
    "# to reproduce LoG with Dog we need sigma_big = 1.6 * sigma_small\n",
    "sigma_xy_small = sigma_xy / 1.6**(1/2)\n",
    "sigma_xy_large = sigma_xy * 1.6**(1/2)\n",
    "sigma_z_small = sigma_z / 1.6**(1/2)\n",
    "sigma_z_large = sigma_z * 1.6**(1/2)\n",
    "\n",
    "filter_sigma_small = (sigma_z_small, sigma_xy_small, sigma_xy_small)\n",
    "filter_sigma_large = (sigma_z_large, sigma_xy_large, sigma_xy_large)\n",
    "\n",
    "print(f\"  - sigma_xy: {np.round(sigma_xy, 3)}  \")\n",
    "print(f\"  - sigma_z: {np.round(sigma_z, 3)}  \")\n",
    "print(f\"  - sigma_xy_small: {np.round(sigma_xy_small, 3)}  \")\n",
    "print(f\"  - sigma_xy_large: {np.round(sigma_xy_large, 3)}  \")\n",
    "print(f\"  - sigma_z_small: {np.round(sigma_z_small, 3)}  \")\n",
    "print(f\"  - sigma_z_large: {np.round(sigma_z_large, 3)}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbb6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'localize_skewed' from '/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/localize_skewed.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(localize_skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_kernel_skewed(sigmas, dc, theta, dstage, sigma_cutoff=2):\n",
    "    pixel_sizes = (dc, dc, dc)\n",
    "    kernel = localize.get_filter_kernel(sigmas, pixel_sizes, sigma_cutoff)\n",
    "    kernel = ipp.deskew(kernel, theta, distance=dstage, pixel_size=dc)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "def get_filter_kernel_skewed(sigmas, dc, theta, dstage, sigma_cutoff=2):\n",
    "    \"\"\"\n",
    "    Get gaussian filter convolution kernel in skewed coordinates\n",
    "\n",
    "    :param sigmas: (sz, sy, sx) in the same units as dc and stage\n",
    "    :param dc: pixel size\n",
    "    :param theta: angle in radians\n",
    "    :param dstage: stage step\n",
    "    :param sigma_cutoff: number of standard deviations to include in the filter. This parameter determines the fitler size\n",
    "    :return kernel:\n",
    "    \"\"\"\n",
    "    # normalize everything to camera pixel size\n",
    "    sigma_x_pix = sigmas[2] / dc\n",
    "    sigma_y_pix = sigmas[2] / dc\n",
    "    sigma_z_pix = sigmas[0] / dc\n",
    "    nk_x = 2 * int(np.round(sigma_x_pix * sigma_cutoff)) + 1\n",
    "    nk_y = 2 * int(np.round(sigma_y_pix * sigma_cutoff)) + 1\n",
    "    nk_z = 2 * int(np.round(sigma_z_pix * sigma_cutoff)) + 1\n",
    "    # determine how large the OPM geometry ROI needs to be to fit the desired filter\n",
    "    roi_sizes = get_skewed_roi_size([nk_z, nk_y, nk_x], theta, 1, dstage / dc, ensure_odd=True)\n",
    "\n",
    "    # get coordinates to evaluate kernel at\n",
    "    xk, yk, zk = get_skewed_coords(roi_sizes, 1, dstage / dc, theta)\n",
    "    xk = xk - np.mean(xk)\n",
    "    yk = yk - np.mean(yk)\n",
    "    zk = zk - np.mean(zk)\n",
    "\n",
    "    kernel = np.exp(-xk ** 2 / 2 / sigma_x_pix ** 2 - yk ** 2 / 2 / sigma_y_pix ** 2 - zk ** 2 / 2 / sigma_z_pix ** 2)\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ef88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_x_pix: 1.1136660138332255\n",
      "sigma_y_pix: 1.1136660138332255\n",
      "sigma_z_pix: 5.1027567891004155\n",
      "nk_x: 7\n",
      "nk_y: 7\n",
      "nk_z: 31\n",
      "roi_sizes: [11, 63, 7]\n",
      "xk shape: (1, 1, 7)\n",
      "yk shape: (11, 63, 1)\n",
      "zk shape: (1, 63, 1)\n"
     ]
    }
   ],
   "source": [
    "sigmas = filter_sigma_small\n",
    "sigma_cutoff = 3\n",
    "\n",
    "# normalize everything to camera pixel size\n",
    "sigma_x_pix = sigmas[2] / dc\n",
    "sigma_y_pix = sigmas[2] / dc\n",
    "sigma_z_pix = sigmas[0] / dc\n",
    "print('sigma_x_pix:', sigma_x_pix)\n",
    "print('sigma_y_pix:', sigma_y_pix)\n",
    "print('sigma_z_pix:', sigma_z_pix)\n",
    "nk_x = 2 * int(np.round(sigma_x_pix * sigma_cutoff)) + 1\n",
    "nk_y = 2 * int(np.round(sigma_y_pix * sigma_cutoff)) + 1\n",
    "nk_z = 2 * int(np.round(sigma_z_pix * sigma_cutoff)) + 1\n",
    "print('nk_x:', nk_x)\n",
    "print('nk_y:', nk_y)\n",
    "print('nk_z:', nk_z)\n",
    "# determine how large the OPM geometry ROI needs to be to fit the desired filter\n",
    "roi_sizes = localize_skewed.get_skewed_roi_size([nk_z, nk_y, nk_x], theta, 1, dstage / dc, ensure_odd=True)\n",
    "print('roi_sizes:', roi_sizes)\n",
    "\n",
    "# get coordinates to evaluate kernel at\n",
    "xk, yk, zk = localize_skewed.get_skewed_coords(roi_sizes, 1, dstage / dc, theta)\n",
    "print('xk shape:', xk.shape)\n",
    "print('yk shape:', yk.shape)\n",
    "print('zk shape:', zk.shape)\n",
    "# xk = xk - np.mean(xk)\n",
    "# yk = yk - np.mean(yk)\n",
    "# zk = zk - np.mean(zk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb39a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5393d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kernel_small_straight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb Cell 122'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000121?line=20'>21</a>\u001b[0m viewer\u001b[39m.\u001b[39madd_image(kernel_small, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkernel small\u001b[39m\u001b[39m'\u001b[39m, colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, blending\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madditive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000121?line=21'>22</a>\u001b[0m viewer\u001b[39m.\u001b[39madd_image(kernel_large, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkernel large\u001b[39m\u001b[39m'\u001b[39m, colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, blending\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madditive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000121?line=22'>23</a>\u001b[0m viewer\u001b[39m.\u001b[39madd_image(kernel_small_straight, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkernel small traight\u001b[39m\u001b[39m'\u001b[39m, colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, blending\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madditive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000121?line=23'>24</a>\u001b[0m viewer\u001b[39m.\u001b[39madd_image(kernel_large_straight, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkernel large traight\u001b[39m\u001b[39m'\u001b[39m, colormap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, blending\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madditive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline.ipynb#ch0000121?line=24'>25</a>\u001b[0m viewer\u001b[39m.\u001b[39madd_image(img, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m, blending\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madditive\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kernel_small_straight' is not defined"
     ]
    }
   ],
   "source": [
    "# pixel_sizes = 2# / 0.115\n",
    "# dstage = .4\n",
    "\n",
    "# kernel_small = localize_skewed.get_filter_kernel_skewed(filter_sigma_small, pixel_sizes, theta, dstage=dstage, sigma_cutoff=3)\n",
    "# kernel_large = localize_skewed.get_filter_kernel_skewed(filter_sigma_large, pixel_sizes, theta, dstage=dstage, sigma_cutoff=3)\n",
    "kernel_small = localize_skewed.get_filter_kernel_skewed(filter_sigma_small, dc, theta, dstage, sigma_cutoff=3)\n",
    "kernel_large = localize_skewed.get_filter_kernel_skewed(filter_sigma_large, dc, theta, dstage, sigma_cutoff=3)\n",
    "# kernel_small = get_filter_kernel_skewed(filter_sigma_small, dc, theta, dstage, sigma_cutoff=3)\n",
    "# kernel_large = get_filter_kernel_skewed(filter_sigma_large, dc, theta, dstage, sigma_cutoff=3)\n",
    "# print(kernel_large.sum())\n",
    "# kernel_small = np.flip(np.swapaxes(kernel_small, 0, 1), axis=0)\n",
    "# kernel_large = np.flip(np.swapaxes(kernel_large, 0, 1), axis=0)\n",
    "kernel_small = np.flip(kernel_small, axis=0)\n",
    "kernel_large = np.flip(kernel_large, axis=0)\n",
    "\n",
    "# pixel_sizes = (dc, dc, dc)\n",
    "# kernel_small_straight = localize.get_filter_kernel(filter_sigma_small, pixel_sizes, sigma_cutoff=2)\n",
    "# kernel_large_straight = localize.get_filter_kernel(filter_sigma_large, pixel_sizes, sigma_cutoff=2)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(kernel_small, name='kernel small', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large, name='kernel large', colormap='red', blending='additive')\n",
    "viewer.add_image(kernel_small_straight, name='kernel small traight', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_straight, name='kernel large traight', colormap='red', blending='additive')\n",
    "viewer.add_image(img, name='img', blending='additive')\n",
    "\n",
    "# %%Can we skip the second convulotion with an \"normalized\" kernel?\n",
    "# im_fct = scipy.signal.fftconvolve(img, kernel_small, mode=\"same\") / scipy.signal.fftconvolve(np.ones(img.shape), kernel_small, mode=\"same\")\n",
    "# kernel_small_normalized = kernel_small - kernel_small.mean()\n",
    "# im_normalized = scipy.signal.fftconvolve(img, kernel_small_normalized, mode=\"same\")\n",
    "\n",
    "\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(im_fct, name='im_fct')\n",
    "# viewer.add_image(im_normalized, name='im_normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d74f5",
   "metadata": {},
   "source": [
    "#### Make hand tilted gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac7efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x7fd34c081e20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_sizes = (dc, dc, dc)\n",
    "sigmas_small = np.array(filter_sigma_small)\n",
    "sigmas_large = np.array(filter_sigma_large)\n",
    "kernel_small_straight = localize.get_filter_kernel(sigmas_small, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_large_straight = localize.get_filter_kernel(sigmas_large, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_small_tilted = scipy.ndimage.rotate(kernel_small_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "kernel_large_tilted = scipy.ndimage.rotate(kernel_large_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(kernel_small_tilted, name='kernel small tilted', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_tilted, name='kernel large tilted', colormap='red', blending='additive')\n",
    "viewer.add_image(img, name='img', blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81e76a",
   "metadata": {},
   "source": [
    "Need to take into account stage displacement, which \"elongates\" the image in one direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x7fd33ef7dfa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilation_coef = dstage / dc\n",
    "dilation_matrix = np.diag([dilation_coef, 1, 1])\n",
    "\n",
    "kernel_small_dilated = scipy.ndimage.affine_transform(kernel_small_tilted, dilation_matrix)\n",
    "kernel_large_dilated = scipy.ndimage.affine_transform(kernel_large_tilted, dilation_matrix)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(kernel_small_tilted, name='kernel small tilted', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_tilted, name='kernel large tilted', colormap='red', blending='additive')\n",
    "viewer.add_image(kernel_small_dilated, name='kernel small dilated', colormap='bop blue', blending='additive')\n",
    "viewer.add_image(kernel_large_dilated, name='kernel large dilated', colormap='bop orange', blending='additive')\n",
    "viewer.add_image(img, name='img', blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dea21f",
   "metadata": {},
   "source": [
    "The gaussian match the spots' size and orientation, but now we have again this pattern after the shear transformation.  \n",
    "We may need to generate a gaussian with a bigger sigma_z and rotate it by a higher angle to have an equivalent kernel, but without stripes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e81793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shear_sigma_theta(sigma_0, theta_0, coef):\n",
    "    \"\"\"\n",
    "    Compute new hypothenuse and angle given by sigma and theta\n",
    "    after dilating the opposite side of theta by a coefficient.\n",
    "    \"\"\"\n",
    "    # side that is elongated\n",
    "    L0 = sigma_0 * np.sin(theta_0)\n",
    "    # angle contacting the hypothenuse, opposite to sheared side.\n",
    "    d = sigma_0 * np.cos(theta_0)\n",
    "    # elongated side\n",
    "    L1 = coef * L0\n",
    "    # elongated hypothenuse\n",
    "    sigma_1 = (L1**2 + d**2)**0.5\n",
    "    # new angle\n",
    "    theta_1 = np.arcsin(L1 / sigma_1)\n",
    "    \n",
    "    return sigma_1, theta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac88c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0000000000000004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / np.sin(30/180*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf335a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilation_coef: 6.9565217391304355\n",
      "theta_elongated: 76.01864938615019\n"
     ]
    }
   ],
   "source": [
    "# need fator of more or less 1.5 to match closer the tilt of spots\n",
    "dilation_coef = dstage / dc / np.sin(30/180*np.pi) # * 1.5\n",
    "sigma_z_small_elongated, theta_elongated = shear_sigma_theta(filter_sigma_small[0], theta, dilation_coef)\n",
    "sigma_z_large_elongated, _ = shear_sigma_theta(filter_sigma_large[0], theta, dilation_coef)\n",
    "\n",
    "theta_elongated = np.abs(theta_elongated * 180 / np.pi)\n",
    "print(f\"dilation_coef: {dilation_coef}\")\n",
    "print(f\"theta_elongated: {theta_elongated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x7fd33f7549d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive tilt\n",
    "kernel_small_straight = localize.get_filter_kernel(sigmas_small, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_large_straight = localize.get_filter_kernel(sigmas_large, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_small_raw_tilted = scipy.ndimage.rotate(kernel_small_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "kernel_large_raw_tilted = scipy.ndimage.rotate(kernel_large_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "\n",
    "# shear\n",
    "sigmas_small_elongated = np.array(sigmas_small)\n",
    "sigmas_small_elongated[0] = sigma_z_small_elongated\n",
    "sigmas_large_elongated = np.array(sigmas_large)\n",
    "sigmas_large_elongated[0] = sigma_z_large_elongated\n",
    "\n",
    "kernel_small_straight = localize.get_filter_kernel(sigmas_small_elongated, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_large_straight = localize.get_filter_kernel(sigmas_large_elongated, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_small_tilted = scipy.ndimage.rotate(kernel_small_straight, angle=theta_elongated, axes=(1, 0), reshape=True)\n",
    "kernel_large_tilted = scipy.ndimage.rotate(kernel_large_straight, angle=theta_elongated, axes=(1, 0), reshape=True)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(kernel_small_raw_tilted, name='kernel small raw tilted', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_raw_tilted, name='kernel large raw tilted', colormap='red', blending='additive')\n",
    "viewer.add_image(kernel_small_tilted, name='kernel small tilted', colormap='bop blue', blending='additive')\n",
    "viewer.add_image(kernel_large_tilted, name='kernel large tilted', colormap='bop orange', blending='additive')\n",
    "viewer.add_image(img, name='img', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f048fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_small = kernel_small_tilted\n",
    "kernel_large = kernel_large_tilted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa671ef4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_high_pass = localize.filter_convolve(img, kernel_small, use_gpu=False)\n",
    "img_low_pass = localize.filter_convolve(img, kernel_large, use_gpu=False)\n",
    "# img_high_pass = localize.filter_convolve(img, np.flip(kernel_small, axis=1), use_gpu=False)\n",
    "# img_low_pass = localize.filter_convolve(img, np.flip(kernel_large, axis=1), use_gpu=False)\n",
    "img_filtered = img_high_pass - img_low_pass\n",
    "del img_high_pass\n",
    "del img_low_pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d59183",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img_filtered' at 0x7fd33f358400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "# viewer.add_image(img_high_pass, name='img_high_pass')\n",
    "# viewer.add_image(img_low_pass, name='img_low_pass')\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b23b9",
   "metadata": {},
   "source": [
    "Jump to section Threshold DoG or run next section about squeezing the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a597f",
   "metadata": {},
   "source": [
    "#### Squeeze image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e42a37",
   "metadata": {},
   "source": [
    "Since the image is kind of elongated in the z (and y) direction, a different way than making smooth tilted gaussian kernel is to \"squeeze back\" the image, hoping to get smooth spots, or spots with less intensity modulation along their longest axis, to avoid detecting several local maxima per spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8951eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation_coef = dstage / dc\n",
    "dilation_matrix = np.diag([1/dilation_coef, 1, 1])\n",
    "\n",
    "img_squeezed = scipy.ndimage.affine_transform(img, dilation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img', blending='additive')\n",
    "viewer.add_image(img_squeezed, name='img squeezed', blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c371c86",
   "metadata": {},
   "source": [
    "We still \"cubes\" within spots, but there is no intensity fluctuation along spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive tilt\n",
    "kernel_small_straight = localize.get_filter_kernel(sigmas_small, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_large_straight = localize.get_filter_kernel(sigmas_large, pixel_sizes, sigma_cutoff=3)\n",
    "kernel_small_raw_tilted = scipy.ndimage.rotate(kernel_small_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "kernel_large_raw_tilted = scipy.ndimage.rotate(kernel_large_straight, angle=30, axes=(1, 0), reshape=True)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(kernel_small_raw_tilted, name='kernel small raw tilted', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_raw_tilted, name='kernel large raw tilted', colormap='red', blending='additive')\n",
    "viewer.add_image(img_squeezed, name='img squeezed', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e43d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3f124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e80037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc43cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28da5a49",
   "metadata": {},
   "source": [
    "### Threshold DoG and local max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold found with Napari\n",
    "dog_thresh = 3\n",
    "img_filtered[img_filtered < dog_thresh] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56315659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 39, 5)\n"
     ]
    }
   ],
   "source": [
    "# footprint = localize.get_max_filter_footprint(min_separations=min_separations, drs=pixel_sizes)\n",
    "# # fit roi size\n",
    "roi_size = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "# # assume points closer together than this come from a single bead\n",
    "min_spot_sep = np.array((3 * sigma_z, 3 * sigma_xy))\n",
    "dz_min, dxy_min = min_spot_sep\n",
    "footprint = localize_skewed.get_skewed_footprint((dz_min, dxy_min, dxy_min), dc, dstage, theta)\n",
    "print(footprint.shape)\n",
    "# min_separations = footprint.shape # (10, 3, 3)\n",
    "# array of size nz, ny, nx of True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'img' at 0x7fd2f57b1fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(np.flip(footprint, axis=0), name='footprint', blending='additive')\n",
    "viewer.add_image(kernel_small_raw_tilted, name='kernel small raw tilted', colormap='green', blending='additive')\n",
    "viewer.add_image(kernel_large_raw_tilted, name='kernel large raw tilted', colormap='red', blending='additive')\n",
    "viewer.add_image(kernel_small_tilted, name='kernel small tilted', colormap='bop blue', blending='additive')\n",
    "viewer.add_image(kernel_large_tilted, name='kernel large tilted', colormap='bop orange', blending='additive')\n",
    "viewer.add_image(img, name='img', blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4615833",
   "metadata": {},
   "source": [
    "The footprint needs to be flipped.  \n",
    "It's a big one, maybe try a smaller one latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could remove the thresholding within each find_peak_candidates call\n",
    "# no: ndimage.maximum_filter returns same image size with real values, need image == im_max\n",
    "# thus need to filter with threshold to avoid zeros or low values\n",
    "# TODO: use gradient on whole image could speed up global process\n",
    "centers_guess_inds, amps = localize.find_peak_candidates(img_filtered, np.flip(footprint, axis=0), threshold=dog_thresh, use_gpu_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70604238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   3, 500],\n",
       "       [  0,   6, 143],\n",
       "       [  0,   9, 468],\n",
       "       ...,\n",
       "       [799, 212, 466],\n",
       "       [799, 218, 474],\n",
       "       [799, 220, 121]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_guess_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3716, 3)\n"
     ]
    }
   ],
   "source": [
    "print(centers_guess_inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'local maxis' at 0x7fd33e5f0e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5e695",
   "metadata": {},
   "source": [
    "### Fit gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi small: (34, 109, 7)\n",
      "roi large: (53, 174, 11)\n",
      "Peter's fit_roi_sizes: [15 65 17]\n"
     ]
    }
   ],
   "source": [
    "roi_size_realspace = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "fit_roi_sizes = np.array(localize_skewed.get_skewed_roi_size(roi_size_realspace, theta, dc, dstage, ensure_odd=True))\n",
    "print(\"roi small:\", kernel_small.shape)\n",
    "print(\"roi large:\", kernel_large.shape)\n",
    "print(\"Peter's fit_roi_sizes:\", fit_roi_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py:376: RuntimeWarning: invalid value encountered in true_divide\n",
      "  centers_unique[counter] = np.nansum(centers_unique[combine] * weights[combine][:, None], axis=0, dtype=float) / denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3716 points separated by dxy > 0.486 and dz > 2.2268\n"
     ]
    }
   ],
   "source": [
    "# fit_roi_sizes = np.array([1.3, 1, 1]) * np.array([sz, sy, sx])\n",
    "fit_roi_sizes = 1 * np.array(kernel_small.shape) #np.array([sz, sy, sx])\n",
    "# This method gives ROIs orthogonal to spots:\n",
    "# roi_size_realspace = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "# fit_roi_sizes = np.array(localize_skewed.get_skewed_roi_size(roi_size_realspace, theta, dc, dstage, ensure_odd=True))\n",
    "# min_fit_roi_sizes = fit_roi_sizes * 0.7\n",
    "min_fit_roi_sizes = fit_roi_sizes * 0.75\n",
    "\n",
    "\n",
    "# average multiple points too close together\n",
    "# quite long and not so efficient to fuse points\n",
    "# either discard or tweak parameters\n",
    "roi_coords, roi_sizes = get_roi_coordinates(\n",
    "    centers = centers_guess_inds, \n",
    "    sizes = fit_roi_sizes, \n",
    "    max_coords_val = np.array(img.shape) - 1, \n",
    "    min_sizes = [0, 0, 0],\n",
    ")\n",
    "centers_guess = roi_coords[:, 0, :] + (roi_sizes / 2)\n",
    "centers_guess = centers_guess.astype(int)\n",
    "inds = np.ravel_multi_index(centers_guess.transpose(), img_filtered.shape)\n",
    "weights = img_filtered.ravel()[inds]\n",
    "# weights = img_filtered[centers_guess]\n",
    "centers_guess, inds_comb = localize.filter_nearby_peaks(centers_guess, dxy_min, dz_min, weights=weights,\n",
    "                                                        mode=\"average\")\n",
    "\n",
    "amps = amps[inds_comb]\n",
    "print(\"Found %d points separated by dxy > %0.5g and dz > %0.5g\" %\n",
    "      (len(centers_guess), dxy_min, dz_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8666220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[                   8,                   28,                  499],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       ...,\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc27cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_coords, roi_sizes = get_roi_coordinates(\n",
    "    centers = centers_guess_inds, \n",
    "    sizes = fit_roi_sizes, \n",
    "    max_coords_val = np.array(img.shape) - 1, \n",
    "    min_sizes = min_fit_roi_sizes,\n",
    ")\n",
    "nb_rois = roi_coords.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2454"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9384938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[                   8,                   28,                  499],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       ...,\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808],\n",
       "       [-9223372036854775808, -9223372036854775808, -9223372036854775808]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb91361",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_points(centers_guess, name='centers_guess', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(roi_coords[:, 0, :], name='ROI start', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(roi_coords[:, 1, :], name='ROI end', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee590c55",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# # all_rois = np.stack(extract_ROI(img, roi_coords[i]) for i in range(nb_rois))\n",
    "# # viewer.add_image(all_rois, name='all rois')\n",
    "# for i in range(nb_rois):\n",
    "#     roi = extract_ROI(img, roi_coords[i])\n",
    "#     viewer.add_image(roi, name=f'roi {i}', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af220460",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fitted = img\n",
    "viewer = napari.Viewer()\n",
    "for i in range(20):\n",
    "    roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "    viewer.add_image(roi, name=f'roi {i}', visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc56462",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "# im_fitted = img_high_pass - img_low_pass\n",
    "im_fitted = img\n",
    "\n",
    "roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "# roi_gauss = extract_ROI(img_high_pass, roi_coords[i])\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(roi, name=f'roi {i}')\n",
    "# viewer.add_image(roi_gauss, name='roi gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde91dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# centers_guess = (roi_sizes / 2)\n",
    "centers_guess = roi_sizes / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414126d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = np.array([\n",
    "    amps[i], \n",
    "    centers_guess[i, 2],\n",
    "    centers_guess[i, 1],\n",
    "    centers_guess[i, 0],\n",
    "    sigma_xy, \n",
    "    sigma_z, \n",
    "    roi.min(),\n",
    "])\n",
    "print(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085b6ad",
   "metadata": {},
   "source": [
    "Do we finally use `get_roi_mask` to set to 0 or minimum of image the corners of the ROI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta already defined as 30 * np.pi / 180\n",
    "\n",
    "fit_results = localize.fit_gauss_roi(\n",
    "    roi, \n",
    "    (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "    init_params,\n",
    "#     estimator=\"LSE\",\n",
    "#     model=\"gaussian\",\n",
    "    sf=1, \n",
    "    dc=dc, \n",
    "    angles=(0., theta, 0.),\n",
    "#     use_gpu=False,\n",
    ")\n",
    "fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = fit_results['fit_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd14ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(roi, name='roi')\n",
    "viewer.add_image(roi_gauss, name='roi gauss')\n",
    "viewer.add_points([center_z, center_y, center_x], name='fitted center', blending='additive', size=2, face_color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e423d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using img_high_pass or img_filtered gives really bad results\n",
    "# # I'd like to understand why fitted centered are all shifted\n",
    "# im_fitted = img #img_high_pass - img_low_pass # img\n",
    "\n",
    "# fit_results_rois = np.zeros((nb_rois, 8))\n",
    "# for i in range(nb_rois):\n",
    "#     # extract ROI\n",
    "#     roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "#     # fit gaussian in ROI\n",
    "#     init_params = np.array([\n",
    "#         amps[i], \n",
    "#         centers_guess[i, 2],\n",
    "#         centers_guess[i, 1],\n",
    "#         centers_guess[i, 0],\n",
    "#         sigma_xy, \n",
    "#         sigma_z, \n",
    "#         roi.min(),\n",
    "#     ])\n",
    "#     fit_results_roi = localize.fit_gauss_roi(\n",
    "#         roi, \n",
    "#         (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "#         init_params,\n",
    "#     )\n",
    "#     # amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset\n",
    "#     fit_results_rois[i, :7] = fit_results_roi['fit_params']\n",
    "#     fit_results_rois[i, 7] = fit_results_roi['chi_squared']\n",
    "# # add origin coordinates of each ROI\n",
    "# centers = fit_results_rois[:, 1:4] + roi_coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using img_high_pass or img_filtered gives really bad results\n",
    "# I'd like to understand why fitted centered are all shifted\n",
    "im_fitted = img #img_high_pass - img_low_pass # img\n",
    "\n",
    "amplitudes = []\n",
    "centers = []\n",
    "sigmas = []\n",
    "chi_squareds = []\n",
    "all_res = []\n",
    "for i in range(nb_rois):\n",
    "    # extract ROI\n",
    "    roi = extract_ROI(im_fitted, roi_coords[i])\n",
    "    # fit gaussian in ROI\n",
    "    init_params = np.array([\n",
    "        amps[i], \n",
    "        centers_guess[i, 2],\n",
    "        centers_guess[i, 1],\n",
    "        centers_guess[i, 0],\n",
    "        sigma_xy, \n",
    "        sigma_z, \n",
    "        roi.min(),\n",
    "    ])\n",
    "    fit_results = localize.fit_gauss_roi(\n",
    "        roi, \n",
    "        (localize.get_coords(roi_sizes[i], drs=[1, 1, 1])), \n",
    "        init_params,\n",
    "        fixed_params=np.full_like(init_params, False),\n",
    "    )\n",
    "    amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = fit_results['fit_params']\n",
    "    amplitudes.append(amplitude)\n",
    "    centers.append([center_z, center_y, center_x])\n",
    "    sigmas.append([sigma_xy, sigma_z])\n",
    "    chi_squareds.append(fit_results['chi_squared'])\n",
    "    all_res.append(fit_results['fit_params'])\n",
    "#     print(fit_results)\n",
    "# add origin coordinates of each ROI\n",
    "centers = np.array(centers) + roi_coords[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86369b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_res)[:,-4:]\n",
    "# np.array(all_res)[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, name='img')\n",
    "viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(centers_guess_inds, name='local maxis', blending='additive', size=3, face_color='r')\n",
    "viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color='g')\n",
    "# viewer.add_points(centers, name='fitted centers', blending='additive', size=3, face_color=chi_squareds, face_colormap=cmap); # napari colormap doesn't work\n",
    "# viewer.add_points(centers, name='fitted centers chi squared', blending='additive', size=3, face_color=chi_colors)\n",
    "# viewer.add_points(centers, name='fitted centers sigma xy', blending='additive', size=3, face_color=sigma_xy_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a5a15",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee692a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "improcess",
   "language": "python",
   "name": "improcess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
