{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot finding pipeline - physics-based, on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5ff34",
   "metadata": {},
   "source": [
    "Pipeline to find spots, using Peter Brown's functions for physics priors, using GPU, and running on several tiles in parallel.\n",
    "The global plan is:\n",
    "  - [x] apply the pipeline to a single tile, non skewed\n",
    "    - [x] extract single ct xyz tile with spots\n",
    "  - [ ] handle inputs to use pixel guesses from users instead of physics inputs\n",
    "  - [ ] add support for skewed tiles\n",
    "    - [ ] extract tilted tile\n",
    "  - [ ] adapt napari-spot-detection plugin to this pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900036aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "from tifffile import tifffile\n",
    "import zarr\n",
    "import dask.array as da\n",
    "from dask_image.imread import imread\n",
    "from dask import delayed\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "from pycromanager import Dataset\n",
    "from napari.qt.threading import thread_worker\n",
    "# from magicgui import magicgui\n",
    "# from matplotlib.colors import PowerNorm, LinearSegmentedColormap, Normalize\n",
    "# from tiler import Tiler\n",
    "# from tysserand import tysserand as ty\n",
    "# from mosna import mosna as mo\n",
    "\n",
    "import localize_psf.rois as roi_fns\n",
    "from localize_psf import fit\n",
    "from localize_psf import data_io\n",
    "import localize_psf.fit_psf as psf\n",
    "from localize_psf import localize\n",
    "import image_post_processing as ipp\n",
    "from image_post_processing import deskew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784cb4d",
   "metadata": {},
   "source": [
    "## On single cartesian volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed8710",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opened                 \n"
     ]
    }
   ],
   "source": [
    "dir_load = Path('../../Data/20210825a_sina_widefield')\n",
    "round = 0\n",
    "channel = 2\n",
    "tile = 1\n",
    "\n",
    "path_metadata = dir_load / f'r000{round}_scan_metadata.csv'\n",
    "path_im = dir_load / f'sina_10gene_panel_r000{round}_xyz000{tile}_1'\n",
    "dataset = Dataset(str(path_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'root_name': 'sina_10gene_panel',\n",
       " 'scan_type': 'iterative-widefield',\n",
       " 'theta': '',\n",
       " 'scan_step_um': '',\n",
       " 'pixel_size_um': 0.065,\n",
       " 'axial_step_um': 0.25,\n",
       " 'y_pixels': 2048,\n",
       " 'x_pixels': 2048,\n",
       " 'exposure_ms': 500.0,\n",
       " 'camera': 'BSI_Express',\n",
       " 'readout_mode': '11bit_sensitive',\n",
       " 'num_r': 8,\n",
       " 'num_y': 49,\n",
       " 'num_z': 121,\n",
       " 'num_ch': 3,\n",
       " 'scan_axis_positions': '',\n",
       " '405_active': False,\n",
       " '488_active': True,\n",
       " '561_active': True,\n",
       " '635_active': True,\n",
       " '730_active': False,\n",
       " '405_power': 0.0,\n",
       " '488_power': 1.0,\n",
       " '561_power': 49.6098,\n",
       " '635_power': 50.0,\n",
       " '730_power': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = data_io.read_metadata(path_metadata)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################\n",
    "# load/set scan parameters\n",
    "# ###############################\n",
    "metadata = data_io.read_metadata(path_metadata)\n",
    "\n",
    "scan_type = metadata[\"scan_type\"]\n",
    "if scan_type == 'iterative-widefield':\n",
    "    nt = metadata[\"num_r\"]\n",
    "    nyp = metadata[\"y_pixels\"]\n",
    "    nxp = metadata[\"x_pixels\"]\n",
    "    dc = metadata['pixel_size_um']\n",
    "    dstage = metadata['axial_step_um']\n",
    "    # do we need this for later analyses?:\n",
    "    # theta = 90 * np.pi / 180\n",
    "    # normal = np.array([0, -np.sin(theta), np.cos(theta)])  # normal of camera pixel\n",
    "\n",
    "    num_r = metadata['num_r']\n",
    "    num_y = metadata['num_y']\n",
    "    num_z = metadata['num_z']\n",
    "    num_ch = metadata['num_ch']\n",
    "    nimgs_per_vol = num_z  # check that\n",
    "\n",
    "    # trapezoid volume\n",
    "    volume_um3 = (dstage * nimgs_per_vol) * (dc * nyp) * (dc * nxp)\n",
    "else:\n",
    "    nt = metadata[\"num_t\"]\n",
    "    nyp = metadata[\"y_pixels\"]\n",
    "    nxp = metadata[\"x_pixels\"]\n",
    "    dc = metadata[\"pixel_size\"] / 1000\n",
    "    dstage = metadata[\"scan_step\"] / 1000\n",
    "    theta = metadata[\"theta\"] * np.pi / 180\n",
    "    normal = np.array([0, -np.sin(theta), np.cos(theta)])  # normal of camera pixel\n",
    "\n",
    "    num_r = metadata['num_r']\n",
    "    num_y = metadata['num_y']\n",
    "    num_z = metadata['num_z']\n",
    "    num_ch = metadata['num_ch']\n",
    "    num_images = metadata['scan_axis_positions']\n",
    "    excess_images = metadata['excess_scan_positions']\n",
    "    nimgs_per_vol = num_images + excess_images\n",
    "\n",
    "    # trapezoid volume\n",
    "    volume_um3 = (dstage * nimgs_per_vol) * (dc * np.sin(theta) * nyp) * (dc * nxp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################\n",
    "# load/set parameters for all datasets\n",
    "# ###############################\n",
    "chunk_size_planes = 1000\n",
    "chunk_size_x = 300\n",
    "# chunk_size_planes = 300\n",
    "# chunk_size_x = 150\n",
    "chunk_overlap = 10\n",
    "channel_to_use = [False, True, True]\n",
    "excitation_wavelengths = np.array([0.488, 0.561, 0.635])\n",
    "emission_wavelengths = np.array([0.515, 0.600, 0.680])\n",
    "thresholds = np.array([np.nan, 10, 10])\n",
    "fit_thresholds = np.array([np.nan, 10, 10])\n",
    "na = 1.\n",
    "ni = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    channel id: 3\n"
     ]
    }
   ],
   "source": [
    "# TODO: make genral reader to handle tiff stacks, NDTiffs and zarr arrays given scan parameters\n",
    "ch = 2\n",
    "\n",
    "# load all images\n",
    "imgs = data_io.open_NDTiff(dataset, channels=ch+1)\n",
    "imgs = imgs[51:74, 449:800, 1000:1400]\n",
    "# imgs = img[51:88, 49:756, 746:1409]\n",
    "imgs = np.flip(np.asarray(imgs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexis/.pyenv/versions/3.8.10/envs/improcess/lib/python3.8/site-packages/napari_tools_menu/__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'imgs' at 0x7fb265dc80a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in _make_sigmas:\n",
      "na 1.0\n",
      "ni 1.4\n",
      "lambda_em 0.68\n",
      "self.sigma_z 0.7422713547744596\n",
      "self.sigma_xy 0.1619991731959446\n",
      "-------\n",
      "in _make_roi_sizes\n",
      "dz 0.25\n",
      "dxy 0.065\n",
      "self.fit_roi_sizes [3 1 1]\n",
      "self.min_roi_sizes_pix [6.5 8.5 8.5]\n",
      "------------\n",
      "in _make_min_spot_sep:\n",
      "sigma_z 0.7422713547744596\n",
      "sigma_xy 0.1619991731959446\n",
      "sigmas_min (0.1855678386936149, 0.04049979329898615)\n",
      "sigmas_max (2.2268140643233787, 0.6479966927837784)\n",
      "filter_sigma_small (0.3711356773872298, 0.04049979329898615, 0.04049979329898615)\n",
      "filter_sigma_large (2.2268140643233787, 0.48599751958783377, 0.48599751958783377)\n",
      "fit_roi_sizes [3 1 1]\n",
      "min_spot_sep (2.2268140643233787, 0.48599751958783377)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(\n",
    "    imgs, \n",
    "    # contrast_limits=[mini, maxi], \n",
    "    # name='ch_' + str(channel), \n",
    "    # # colormap=color, \n",
    "    blending='additive',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 351, 400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(localize)\n",
    "# image coordinates\n",
    "# x, y, z = localize.get_coords(imgs.shape, dc, dstage, theta)\n",
    "z, y, x = localize.get_coords(imgs.shape, [dstage, dc, dc])\n",
    "zb, yb, xb = np.broadcast_arrays(z, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################\n",
    "# identify candidate points in opm data\n",
    "# ###############################\n",
    "# sigma_xy = 0.22 * emission_wavelengths[ch] / na\n",
    "# sigma_z = np.sqrt(6) / np.pi * ni * emission_wavelengths[ch] / na ** 2\n",
    "sigma_xy = psf.na2sxy(na, emission_wavelengths[ch])\n",
    "sigma_z = psf.na2sz(na, emission_wavelengths[ch], ni)\n",
    "\n",
    "# difference of gaussian filer\n",
    "filter_sigma_small = (0.5 * sigma_z, 0.25 * sigma_xy, 0.25 * sigma_xy)\n",
    "filter_sigma_large = (3 * sigma_z, 3 * sigma_xy, 3 * sigma_xy)\n",
    "# fit roi size\n",
    "roi_size = (5 * sigma_z, 12 * sigma_xy, 12 * sigma_xy)\n",
    "# assume points closer together than this come from a single bead\n",
    "min_spot_sep = (3 * sigma_z, 3 * sigma_xy)\n",
    "# exclude points with sigmas outside these ranges\n",
    "sigmas_min = (0.25 * sigma_z, 0.25 * sigma_xy)\n",
    "sigmas_max = (3 * sigma_z, 4 * sigma_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ni 1.4\n",
      "na 1.0\n",
      "lambda_em 0.68\n",
      "sigma_z 0.7422713547744596\n",
      "sigma_xy 0.1619991731959446\n",
      "sigmas_min (0.1855678386936149, 0.04049979329898615)\n",
      "sigmas_max (2.2268140643233787, 0.6479966927837784)\n",
      "filter_sigma_small (0.3711356773872298, 0.04049979329898615, 0.04049979329898615)\n",
      "filter_sigma_large (2.2268140643233787, 0.48599751958783377, 0.48599751958783377)\n",
      "min_spot_sep (2.2268140643233787, 0.48599751958783377)\n"
     ]
    }
   ],
   "source": [
    "print('ni', ni)\n",
    "print('na', na)\n",
    "print('lambda_em', emission_wavelengths[ch])\n",
    "print('sigma_z', sigma_z)\n",
    "print('sigma_xy', sigma_xy)\n",
    "print('sigmas_min', sigmas_min)\n",
    "print('sigmas_max', sigmas_max)\n",
    "print('filter_sigma_small', filter_sigma_small)\n",
    "print('filter_sigma_large', filter_sigma_large)\n",
    "# print('filter_sigma_small', fit_roi_sizes)\n",
    "# print('filter_sigma_small', min_fit_roi_sizes)\n",
    "# print('filter_sigma_large', min_roi_sizes_pix)\n",
    "print('min_spot_sep', min_spot_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do localization\n",
    "# ###################################################\n",
    "# smooth image and remove background with difference of gaussians filter\n",
    "# ###################################################\n",
    "imgs_chunk = imgs\n",
    "\n",
    "drs = [dstage, dc, dc]\n",
    "ks = localize.get_filter_kernel(filter_sigma_small, drs, sigma_cutoff=2)\n",
    "kl = localize.get_filter_kernel(filter_sigma_large, drs, sigma_cutoff=2)\n",
    "imgs_hp = localize.filter_convolve(imgs_chunk, ks, use_gpu=False)\n",
    "imgs_lp = localize.filter_convolve(imgs_chunk, kl, use_gpu=False)\n",
    "imgs_filtered = imgs_hp - imgs_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'imgs_filtered' at 0x7f1e5dcd2550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(imgs, name='imgs', blending='additive')\n",
    "viewer.add_image(imgs_filtered, name='imgs_filtered', blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we don't handle chuncks\n",
    "# x_chunk = x[:, :, ix_start:ix_end]\n",
    "# y_chunk = y[ip_start:ip_end, :, :]\n",
    "# z_chunk = z[:, :, :]\n",
    "x_chunk = x\n",
    "y_chunk = y\n",
    "z_chunk = z\n",
    "\n",
    "y_offset = y_chunk.min()\n",
    "x_offset = x_chunk.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# identify candidate beads\n",
    "# ###################################################\n",
    "\n",
    "dz_min, dxy_min = min_spot_sep\n",
    "min_separations = (dz_min, dxy_min, dxy_min)\n",
    "\n",
    "footprint = localize.get_max_filter_footprint(min_separations, drs)\n",
    "centers_guess_inds, amps = localize.find_peak_candidates(imgs_filtered, footprint, thresholds[ch])\n",
    "\n",
    "# convert to xyz coordinates\n",
    "centers_guess = np.stack((z_chunk[centers_guess_inds[:, 0], 0, 0],\n",
    "                            y_chunk[0, centers_guess_inds[:, 1], 0],\n",
    "                            x_chunk[0, 0, centers_guess_inds[:, 2]]),\n",
    "                            axis=1)\n",
    "# /!\\ check here the order for z/y/x_chunk wrt centers_guess_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 points separated by dxy > 0.486 and dz > 2.2268 in 0.1s\n"
     ]
    }
   ],
   "source": [
    "if len(centers_guess) != 0:\n",
    "    # ###################################################\n",
    "    # average multiple points too close together. Necessary bc if naive threshold, may identify several points\n",
    "    # from same spot. Particularly important if spots have very different brightness levels.\n",
    "    # ###################################################\n",
    "    tstart = time.perf_counter()\n",
    "\n",
    "    inds = np.ravel_multi_index(centers_guess_inds.transpose(), imgs_filtered.shape)\n",
    "    weights = imgs_filtered.ravel()[inds]\n",
    "    centers_guess, inds_comb = localize.filter_nearby_peaks(centers_guess, dxy_min, dz_min, weights=weights,\n",
    "                                                            mode=\"average\")\n",
    "\n",
    "    amps = amps[inds_comb]\n",
    "    print(\"Found %d points separated by dxy > %0.5g and dz > %0.5g in %0.1fs\" %\n",
    "            (len(centers_guess), dxy_min, dz_min, time.perf_counter() - tstart))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(coords_roi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'localize_psf.localize' has no attribute 'get_roi_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb Cellule 21\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m rois \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(rois)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# exclude some regions of roi\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m roi_masks \u001b[39m=\u001b[39m [localize\u001b[39m.\u001b[39mget_roi_mask(c, (np\u001b[39m.\u001b[39minf, \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m roi_size[\u001b[39m1\u001b[39m]), (zrois[ii], yrois[ii], xrois[ii])) \u001b[39mfor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 ii, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(centers_guess)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# mask regions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m xrois, yrois, zrois, img_rois \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m*\u001b[39m[(np\u001b[39m.\u001b[39mexpand_dims(xr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(yr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(zr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(ir[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m xr, yr, zr, ir, rm \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(xrois, yrois, zrois, img_rois, roi_masks)])\n",
      "\u001b[1;32m/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb Cellule 21\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m rois \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(rois)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# exclude some regions of roi\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m roi_masks \u001b[39m=\u001b[39m [localize\u001b[39m.\u001b[39;49mget_roi_mask(c, (np\u001b[39m.\u001b[39minf, \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m roi_size[\u001b[39m1\u001b[39m]), (zrois[ii], yrois[ii], xrois[ii])) \u001b[39mfor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 ii, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(centers_guess)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# mask regions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m xrois, yrois, zrois, img_rois \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m*\u001b[39m[(np\u001b[39m.\u001b[39mexpand_dims(xr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(yr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(zr[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         np\u001b[39m.\u001b[39mexpand_dims(ir[rm], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/notebooks/spot_finding_pipeline_gpu.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m xr, yr, zr, ir, rm \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(xrois, yrois, zrois, img_rois, roi_masks)])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'localize_psf.localize' has no attribute 'get_roi_mask'"
     ]
    }
   ],
   "source": [
    "# ###################################################\n",
    "# prepare ROIs\n",
    "# ###################################################\n",
    "tstart_prep_roi = time.perf_counter()\n",
    "\n",
    "# cut rois out\n",
    "roi_size = roi_fns.get_roi_size(roi_size, dc, dstage, ensure_odd=True)\n",
    "rois, img_rois, coords_roi = zip(*[localize.get_roi(c, imgs_chunk, (z_chunk, y_chunk, x_chunk), roi_size) for c in centers_guess])\n",
    "# xrois, yrois, zrois = coords_roi\n",
    "rois = np.asarray(rois)\n",
    "\n",
    "# exclude some regions of roi\n",
    "roi_masks = [localize.get_roi_mask(c, (np.inf, 0.5 * roi_size[1]), (zrois[ii], yrois[ii], xrois[ii])) for\n",
    "                ii, c in enumerate(centers_guess)]\n",
    "\n",
    "# mask regions\n",
    "xrois, yrois, zrois, img_rois = zip(\n",
    "    *[(np.expand_dims(xr[rm], axis=0),\n",
    "        np.expand_dims(yr[rm], axis=0),\n",
    "        np.expand_dims(zr[rm], axis=0),\n",
    "        np.expand_dims(ir[rm], axis=0))\n",
    "        for xr, yr, zr, ir, rm in zip(xrois, yrois, zrois, img_rois, roi_masks)])\n",
    "\n",
    "# extract guess values\n",
    "with np.errstate(invalid=\"ignore\"):\n",
    "    bgs = np.array([np.mean(r) for r in img_rois])\n",
    "    # why this euclidean distance or std? ---v\n",
    "    sxs = np.array([np.sqrt(np.sum(ir * (xr - cg[2]) ** 2) / np.sum(ir)) for ir, xr, cg in\n",
    "                    zip(img_rois, xrois, centers_guess)])\n",
    "    sys = np.array([np.sqrt(np.sum(ir * (yr - cg[1]) ** 2) / np.sum(ir)) for ir, yr, cg in\n",
    "                    zip(img_rois, yrois, centers_guess)])\n",
    "    sxys = 0.5 * (sxs + sys)\n",
    "    szs = np.array([np.sqrt(np.sum(ir * (zr - cg[0]) ** 2) / np.sum(ir)) for ir, zr, cg in\n",
    "                    zip(img_rois, zrois, centers_guess)])\n",
    "\n",
    "# get initial parameter guesses\n",
    "init_params = np.stack((amps, centers_guess[:, 2],\n",
    "                centers_guess[:, 1],\n",
    "                centers_guess[:, 0],\n",
    "                sxys, szs, bgs), axis=1)\n",
    "\n",
    "print(\"Prepared %d rois and estimated initial parameters in %0.2fs\" % (len(rois), time.perf_counter() - tstart_prep_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ###################################################\n",
    "# # localization\n",
    "# # ###################################################\n",
    "# print(\"Starting localization fitting for %d rois\" % centers_guess.shape[0])\n",
    "# tstart = time.perf_counter()\n",
    "\n",
    "# fit_params, fit_states, chi_sqrs, niters, fit_t = localize.fit_gauss_rois(img_rois, (zrois, yrois, xrois),\n",
    "#                                                                             init_params, estimator=\"LSE\",\n",
    "#                                                                             model=\"gaussian\",\n",
    "#                                                                             sf=1, dc=dc, angles=(0., theta, 0.))\n",
    "\n",
    "# tend = time.perf_counter()\n",
    "# print(\"Localization fitting for %d rois took %0.2fs\" % (len(rois), tend - tstart))\n",
    "\n",
    "# # fitting\n",
    "# fit_results = np.stack((fit_states, chi_sqrs, niters), axis=1)\n",
    "\n",
    "# # ###################################################\n",
    "# # preliminary fitting of results\n",
    "# # ###################################################\n",
    "# tstart = time.perf_counter()\n",
    "\n",
    "# to_keep, conditions, condition_names, filter_settings = localize_skewed.filter_localizations(\n",
    "#     fit_params, init_params, (z_chunk, y_chunk, x_chunk),\n",
    "#     (sigma_z, 3*sigma_xy), min_spot_sep,\n",
    "#     (sigmas_min, sigmas_max),\n",
    "#     fit_thresholds[ch],\n",
    "#     dist_boundary_min=(0.5 * sigma_z, sigma_xy))\n",
    "\n",
    "# print(\"Identified %d/%d plausible localizations in %0.1fs\" % (np.sum(to_keep), to_keep.size, time.perf_counter() - tstart))\n",
    "\n",
    "# # ###################################################\n",
    "# # correct ROIs for full volume\n",
    "# # ###################################################\n",
    "# rois[:, :2] += ip_start\n",
    "# rois[:, 4:] += ix_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Peter's pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'localize_psf.localize' from '/home/alexis/Documents/Pro/Postdoc_ASU/Projects/localize-psf/localize_psf/localize.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(localize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered image in 3.74s\n",
      "identified 380 candidates in 0.19s\n",
      "Found 317 points separated by dxy > 0.486 and dz > 2.2268 in 0.0s\n",
      "Prepared 317 rois and estimated initial parameters in 0.29s\n",
      "starting fitting for 317 rois\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   25.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization took 38.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 out of 317 | elapsed:   38.6s finished\n"
     ]
    }
   ],
   "source": [
    "dxy = dc\n",
    "dz = dstage\n",
    "threshold = thresholds[ch]\n",
    "sigma_bounds = (sigmas_min, sigmas_max)\n",
    "fit_amp_min = 60 #fit_thresholds[ch]\n",
    "\n",
    "(z, y, x), fit_params, init_params, rois = localize.localize_spots(\n",
    "    imgs, dxy, dz, threshold, roi_size, \n",
    "    filter_sigma_small, filter_sigma_large,\n",
    "    min_spot_sep, verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude, center_x, center_y, center_z, sigma_xy, sigma_z, offset = [fit_params[:, i] for i in range(fit_params.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_fit = np.vstack([center_z, center_y, center_x]).T\n",
    "center_fit = center_fit / np.array([dstage, dc, dc])\n",
    "# spots_filtered = spots_guessed[to_keep, :]\n",
    "\n",
    "# invert z orientation\n",
    "# spots_guessed[:, 0] = imgs.shape[0] - spots_guessed[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'center_fit' at 0x7fbb14340070>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(imgs, name='img')\n",
    "# viewer.add_image(img_filtered, name='img_filtered')\n",
    "# viewer.add_image(im_fitted, name='im_fitted')\n",
    "viewer.add_points(center_fit, name='center_fit', blending='additive', size=3, face_color='b')\n",
    "# viewer.add_points(spots_filtered, name='spots_filtered', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that works, let's reproduce the successive steps of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successive steps of Peter's pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# localize_spots(imgs, dxy, dz, threshold, roi_size, filter_sigma_small, filter_sigma_large,\n",
    "#                    min_spot_sep, use_gpu_fit=GPUFIT_AVAILABLE, use_gpu_filter=CUPY_AVAILABLE, verbose=True)\n",
    "\n",
    "dxy = dc\n",
    "dz = dstage\n",
    "threshold = thresholds[ch]\n",
    "sigma_bounds = (sigmas_min, sigmas_max)\n",
    "fit_amp_min = 60 #fit_thresholds[ch]\n",
    "\n",
    "use_gpu_fit=False\n",
    "use_gpu_filter=False\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered image in 4.21s\n"
     ]
    }
   ],
   "source": [
    "# make sure inputs correct types\n",
    "roi_size = np.array(roi_size, copy=True)\n",
    "min_spot_sep = np.array(min_spot_sep, copy=True)\n",
    "filter_sigma_large = np.array(filter_sigma_large, copy=True)\n",
    "filter_sigma_small = np.array(filter_sigma_small, copy=True)\n",
    "\n",
    "# check if is 2D\n",
    "if imgs.ndim == 2:\n",
    "    imgs = np.expand_dims(imgs, axis=0)\n",
    "\n",
    "data_is_2d = imgs.shape[0] == 1\n",
    "\n",
    "if data_is_2d:\n",
    "    roi_size[0] = 0\n",
    "    filter_sigma_large[0] = 0\n",
    "    filter_sigma_small[0] = 0\n",
    "    min_spot_sep[0] = 0\n",
    "\n",
    "# unpack arguments\n",
    "z, y, x = localize.get_coords(imgs.shape, (dz, dxy, dxy))\n",
    "dz_min_sep, dxy_min_sep = min_spot_sep\n",
    "roi_size_pix = roi_fns.get_roi_size(roi_size, dxy, dz, ensure_odd=True)\n",
    "\n",
    "# ###################################\n",
    "# filter images\n",
    "# ###################################\n",
    "tstart = time.perf_counter()\n",
    "\n",
    "ks = localize.get_filter_kernel(filter_sigma_small, (dz, dxy, dxy))\n",
    "kl = localize.get_filter_kernel(filter_sigma_large, (dz, dxy, dxy))\n",
    "imgs_hp = localize.filter_convolve(imgs, ks, use_gpu=use_gpu_filter)\n",
    "imgs_lp = localize.filter_convolve(imgs, kl, use_gpu=use_gpu_filter)\n",
    "imgs_filtered = imgs_hp - imgs_lp\n",
    "\n",
    "if verbose:\n",
    "    print(\"filtered image in %0.2fs\" % (time.perf_counter() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'img_filtered' at 0x7fbb17668580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(imgs_filtered, name='img_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identified 380 candidates in 0.31s\n"
     ]
    }
   ],
   "source": [
    "# ###################################\n",
    "# identify candidate beads\n",
    "# ###################################\n",
    "tstart = time.perf_counter()\n",
    "\n",
    "footprint = localize.get_max_filter_footprint((dz_min_sep, dxy_min_sep, dxy_min_sep), (dz, dxy, dxy))\n",
    "centers_guess_inds, amps = localize.find_peak_candidates(imgs_filtered, footprint, threshold)\n",
    "\n",
    "# real coordinates\n",
    "centers_guess = np.stack((z[centers_guess_inds[:, 0], 0, 0],\n",
    "                            y[0, centers_guess_inds[:, 1], 0],\n",
    "                            x[0, 0, centers_guess_inds[:, 2]]), axis=1)\n",
    "\n",
    "if verbose:\n",
    "    print(\"identified %d candidates in %0.2fs\" % (len(centers_guess_inds), time.perf_counter() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'spots_guessed' at 0x7fbb176685b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spots_guessed = centers_guess / np.array([dstage, dc, dc])\n",
    "viewer.add_points(spots_guessed, name='spots_guessed', blending='additive', size=3, face_color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 317 points separated by dxy > 0.486 and dz > 2.2268 in 0.1s\n",
      "Prepared 317 rois and estimated initial parameters in 0.39s\n"
     ]
    }
   ],
   "source": [
    "# ###################################\n",
    "# identify candidate beads\n",
    "# ###################################\n",
    "if len(centers_guess_inds) == 0:\n",
    "    # return None\n",
    "    pass\n",
    "else:\n",
    "    # ###################################################\n",
    "    # average multiple points too close together. Necessary bc if naive threshold, may identify several points\n",
    "    # from same spot. Particularly important if spots have very different brightness levels.\n",
    "    # ###################################################\n",
    "    tstart = time.perf_counter()\n",
    "\n",
    "    inds = np.ravel_multi_index(centers_guess_inds.transpose(), imgs_filtered.shape)\n",
    "    weights = imgs_filtered.ravel()[inds]\n",
    "    centers_guess, inds_comb = localize.filter_nearby_peaks(centers_guess, dxy_min_sep, dz_min_sep,\n",
    "                                                    weights=weights, mode=\"average\")\n",
    "\n",
    "    amps = amps[inds_comb]\n",
    "    if verbose:\n",
    "        print(\"Found %d points separated by dxy > %0.5g and dz > %0.5g in %0.1fs\" %\n",
    "                (len(centers_guess), dxy_min_sep, dz_min_sep, time.perf_counter() - tstart))\n",
    "\n",
    "    # ###################################################\n",
    "    # prepare ROIs\n",
    "    # ###################################################\n",
    "    tstart = time.perf_counter()\n",
    "\n",
    "    rois, img_rois, coords = zip(*[localize.get_roi(c, imgs, (z, y, x), roi_size_pix) for c in centers_guess])\n",
    "    zrois, yrois, xrois = zip(*coords)\n",
    "    rois = np.asarray(rois)\n",
    "\n",
    "    # extract guess values\n",
    "    bgs = np.array([np.mean(r) for r in img_rois])\n",
    "    sxs = np.array([np.sqrt(np.sum(ir * (xr - cg[2]) ** 2) / np.sum(ir)) for ir, xr, cg in\n",
    "                    zip(img_rois, xrois, centers_guess)])\n",
    "    sys = np.array([np.sqrt(np.sum(ir * (yr - cg[1]) ** 2) / np.sum(ir)) for ir, yr, cg in\n",
    "                    zip(img_rois, yrois, centers_guess)])\n",
    "    sxys = 0.5 * (sxs + sys)\n",
    "\n",
    "    if data_is_2d:\n",
    "        cz_guess = np.zeros(len(img_rois))\n",
    "        szs = np.ones(len(img_rois))\n",
    "    else:\n",
    "        cz_guess = centers_guess[:, 0]\n",
    "        szs = np.array([np.sqrt(np.sum(ir * (zr - cg[0]) ** 2) / np.sum(ir)) for ir, zr, cg in\n",
    "                        zip(img_rois, zrois, centers_guess)])\n",
    "\n",
    "    # get initial parameter guesses\n",
    "    init_params = np.stack((amps,\n",
    "                            centers_guess[:, 2], centers_guess[:, 1], cz_guess,\n",
    "                            sxys, szs, bgs), axis=1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Prepared %d rois and estimated initial parameters in %0.2fs\" %\n",
    "                (len(rois), time.perf_counter() - tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'spots_guessed_merged' at 0x7fbb42800af0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spots_guessed = centers_guess / np.array([dstage, dc, dc])\n",
    "viewer.add_points(spots_guessed, name='spots_guessed_merged', blending='additive', size=3, face_color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting for 317 rois\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   29.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization took 41.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 out of 317 | elapsed:   41.7s finished\n"
     ]
    }
   ],
   "source": [
    "# In the conditional loop:\n",
    "\n",
    "# ###################################################\n",
    "# localization\n",
    "# ###################################################\n",
    "if verbose:\n",
    "    print(\"starting fitting for %d rois\" % centers_guess.shape[0])\n",
    "tstart = time.perf_counter()\n",
    "\n",
    "fixed_params = [False] * 7\n",
    "\n",
    "# if 2D, don't want to fit cz or sz\n",
    "if data_is_2d:\n",
    "    fixed_params[5] = True\n",
    "    fixed_params[3] = True\n",
    "\n",
    "fit_params, fit_states, chi_sqrs, niters, fit_t = localize.fit_gauss_rois(img_rois, (zrois, yrois, xrois),\n",
    "                                                                    init_params, estimator=\"LSE\",\n",
    "                                                                    sf=1, dc=dxy, angles=(0., 0., 0.),\n",
    "                                                                    fixed_params=fixed_params,\n",
    "                                                                    use_gpu=use_gpu_fit)\n",
    "\n",
    "tend = time.perf_counter()\n",
    "if verbose:\n",
    "    print(\"Localization took %0.2fs\" % (tend - tstart))\n",
    "\n",
    "# # ###################################################\n",
    "# # filter fits\n",
    "# # ###################################################\n",
    "# to_keep, conditions, condition_names, filter_settings = \\\n",
    "#     filter_localizations(fit_params, init_params, (z, y, x), fit_dist_max_err, min_spot_sep,\n",
    "#                          sigma_bounds, fit_amp_min, dist_boundary_min)\n",
    "\n",
    "# if verbose:\n",
    "#     print(\"Identified %d likely candidates\" % np.sum(to_keep))\n",
    "\n",
    "# return (z, y, x), fit_params, init_params, rois, to_keep, conditions, condition_names, filter_settings\n",
    "# return (z, y, x), fit_params, init_params, rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'center_fit succ' at 0x7fbb4280b2e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_fit = np.array([fit_params[:, 3], fit_params[:, 2], fit_params[:, 1]]).T\n",
    "# center_fit = np.array([fit_params[:, 1], fit_params[:, 2], fit_params[:, 3]]).T\n",
    "center_fit = center_fit / np.array([dstage, dc, dc])\n",
    "viewer.add_points(center_fit, name='center_fit succ', blending='additive', size=3, face_color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'localize_spots' at 0x7fbb41bad9a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison with localize_spots coordinates\n",
    "center_fit = np.vstack([center_z, center_y, center_x]).T\n",
    "center_fit = center_fit / np.array([dstage, dc, dc])\n",
    "viewer.add_points(center_fit, name='localize_spots', blending='additive', size=3, face_color='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "improcess",
   "language": "python",
   "name": "improcess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fd17c2a3cc45a29e1bfa15b819c9156ecadd08338159e4fde2e7a7ca42dd8d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
